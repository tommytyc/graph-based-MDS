{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tommytyc/anaconda3/envs/test_Tempest/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/tommytyc/anaconda3/envs/test_Tempest/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/tommytyc/anaconda3/envs/test_Tempest/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/tommytyc/anaconda3/envs/test_Tempest/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/tommytyc/anaconda3/envs/test_Tempest/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/tommytyc/anaconda3/envs/test_Tempest/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import  pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "from rouge import Rouge \n",
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"product_desc_dict.pickle\", 'rb') as f:\n",
    "#     prod_desc = pickle.load(f)\n",
    "# with open(\"product_intro_dict.pickle\", 'rb') as f:\n",
    "#     prod_intro = pickle.load(f)\n",
    "# with open(\"product_name_dict.pickle\", 'rb') as f:\n",
    "#     prod_name = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('com_product_intro_word_articles_train.json', 'r') as f:\n",
    "#     intro = json.load(f)\n",
    "# with open('com_product_name_word_flatten_intro_train.json', 'r') as f:\n",
    "#     name = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_tags(htmlstr):\n",
    "#     re_cdata=re.compile('//<!\\[CDATA\\[[^>]*//\\]\\]>',re.I)\n",
    "#     re_script=re.compile('<\\s*script[^>]*>[^<]*<\\s*/\\s*script\\s*>',re.I)\n",
    "#     re_style=re.compile('<\\s*style[^>]*>[^<]*<\\s*/\\s*style\\s*>',re.I)\n",
    "#     re_br=re.compile('<br\\s*?/?>')\n",
    "#     re_h=re.compile('</?\\w+[^>]*>')\n",
    "#     re_comment=re.compile('<!--[^>]*-->')\n",
    "#     s=re_cdata.sub('',htmlstr)\n",
    "#     s=re_script.sub('',s)\n",
    "#     s=re_style.sub('',s)\n",
    "#     s=re_br.sub('',s)\n",
    "#     s=re_h.sub('',s) \n",
    "#     s=re_comment.sub('',s)\n",
    "#     blank_line=re.compile('\\n+')\n",
    "#     s=blank_line.sub('\\n',s)\n",
    "#     s=replaceCharEntity(s)\n",
    "#     return s\n",
    "\n",
    "# def replaceCharEntity(htmlstr):\n",
    "#     CHAR_ENTITIES={'nbsp':' ','160':' ',\n",
    "#                 'lt':'<','60':'<',\n",
    "#                 'gt':'>','62':'>',\n",
    "#                 'amp':'&','38':'&',\n",
    "#                 'quot':'\"','34':'\"',}\n",
    "#     re_charEntity=re.compile(r'&#?(?P<name>\\w+);')\n",
    "#     sz=re_charEntity.search(htmlstr)\n",
    "#     while sz:\n",
    "#         entity=sz.group()\n",
    "#         key=sz.group('name')\n",
    "#         try:\n",
    "#             htmlstr=re_charEntity.sub(CHAR_ENTITIES[key],htmlstr,1)\n",
    "#             sz=re_charEntity.search(htmlstr)\n",
    "#         except KeyError:\n",
    "#             htmlstr=re_charEntity.sub('',htmlstr,1)\n",
    "#             sz=re_charEntity.search(htmlstr)\n",
    "#     return htmlstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_cleaner(data) -> dict:\n",
    "#     new_data = {}\n",
    "#     for key in data:\n",
    "#         new_value = filter_tags(data[key])\n",
    "#         new_data[key] = new_value\n",
    "#     return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prod_desc = data_cleaner(prod_desc)\n",
    "# prod_intro = data_cleaner(prod_intro)\n",
    "# prod_name = data_cleaner(prod_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"clear_product_desc_dict.pickle\", 'wb') as f:\n",
    "#     pickle.dump(prod_desc, f)\n",
    "# with open(\"clear_product_intro_dict.pickle\", 'wb') as f:\n",
    "#     pickle.dump(prod_intro, f)\n",
    "# with open(\"clear_product_name_dict.pickle\", 'wb') as f:\n",
    "#     pickle.dump(prod_name, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"seg_desc.pickle\", 'rb') as f:\n",
    "#     seg_desc = pickle.load(f)\n",
    "# with open(\"seg_intro.pickle\", 'rb') as f:\n",
    "#     seg_intro = pickle.load(f)\n",
    "# with open(\"seg_name.pickle\", 'rb') as f:\n",
    "#     seg_name = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seg_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2Vec_model = gensim.models.Doc2Vec.load(\"./doc2vec_model/doc2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file):\n",
    "    with open(file) as jsonfile:\n",
    "        data = json.load(jsonfile)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(torch.nn.Module): \n",
    "    def __init__(self, w2vmodel): \n",
    "        super().__init__() \n",
    "        self.weights = torch.FloatTensor(w2vmodel.wv.vectors)\n",
    "        self.embedding = nn.Embedding.from_pretrained(self.weights, padding_idx = -1)\n",
    "        self.embedding.requires_grad = False\n",
    "        \n",
    "        # vector for oov \n",
    "        self.oov = torch.nn.Parameter(data=torch.rand(1,250)) \n",
    "        self.oov_index = -1 \n",
    "        self.dim = 250 \n",
    "\n",
    "    def create_embedding(self, arr): \n",
    "        N = arr.shape[0] \n",
    "        mask =  (arr==self.oov_index).long() \n",
    "        mask_ = mask.unsqueeze(dim=1).float() \n",
    "        embed =(1-mask_)*self.embedding((1-mask)*arr) + mask_*(self.oov.expand((N,self.dim))) \n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vmodel = gensim.models.Word2Vec.load('./word2vec/word2vec.model')\n",
    "embedding_model = Embeddings(w2vmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadDocSentEmb(doc_list, doc_idx, sent_num):\n",
    "    \"\"\" Return the embedding of each sentence of a document. If sentence number is less than sent_num, the last part will\n",
    "        be filled by 0.\n",
    "    parameter:\n",
    "        doc_list: every product intro\n",
    "        doc_idx : load which product intro\n",
    "    return: sentence embedding array\n",
    "    \"\"\"\n",
    "    doc_sent = doc_list[doc_idx]\n",
    "    sent_emb_array = []\n",
    "    \n",
    "    for i in range(sent_num):\n",
    "        id_seq = []\n",
    "        if i < len(doc_sent):\n",
    "            sent = doc_sent[i].split()\n",
    "            for word in sent:\n",
    "                try:\n",
    "                    word_id = w2vmodel.wv.vocab[word].index\n",
    "                except KeyError:\n",
    "                    word_id = -1  # deal with OOV\n",
    "                finally:\n",
    "                    id_seq.append(word_id)\n",
    "            sent_emb = embedding_model.create_embedding(torch.tensor(id_seq))\n",
    "        else:\n",
    "            sent_emb = torch.FloatTensor([np.zeros((250,))])\n",
    "        sent_emb_array.append(sent_emb.view(len(sent_emb), 1, 250))\n",
    "    \n",
    "    return sent_emb_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphLoader(data.Dataset):\n",
    "    def __init__(self, mode, root, sent_num=20, sent_len=30, hidden_size=250):\n",
    "        self.root = root\n",
    "        self.inputdata = load_json(root+'com_product_intro_word_articles_'+mode+'.json')\n",
    "        self.golddata = load_json(root+'com_product_name_word_flatten_intro_'+mode+'.json')\n",
    "        self.golddata = self.trans_data(self.golddata)\n",
    "        self.sent_len = sent_len\n",
    "        self.sent_num = sent_num\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(input_size=250, hidden_size=250, batch_first=True)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"return the size of dataset\"\"\"\n",
    "        return len(self.inputdata)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # training\n",
    "        graph = self.create_graph(index) \n",
    "        embedding = self.create_lstm_embedding(self.inputdata, index)\n",
    "        \n",
    "        # ground truth\n",
    "        gold = self.compute_rouge(self.inputdata,self.golddata, index)\n",
    "        gold = torch.FloatTensor(gold)\n",
    "        \n",
    "        return graph, embedding, gold\n",
    "    \n",
    "    def create_graph(self, idx):\n",
    "        \"\"\"Using doc2vec cosine similarity\"\"\"\n",
    "        sentences_list = self.inputdata[idx]\n",
    "        sentence_vectors = []\n",
    "        for i in range(self.sent_num):\n",
    "            if i < len(sentences_list):\n",
    "                v = doc2Vec_model.infer_vector(sentences_list[i].split())\n",
    "            else:\n",
    "                v = np.zeros((250,)) \n",
    "            sentence_vectors.append(v)\n",
    "        sentence_similarity_martix = np.eye(self.sent_num)\n",
    "        for j in range(self.sent_num):\n",
    "            for k in range(self.sent_num):\n",
    "                if j != k:\n",
    "                    sentence_similarity_martix[j][k] = cosine_similarity(sentence_vectors[j].reshape(1,250), sentence_vectors[k].reshape(1,250))[0,0]\n",
    "\n",
    "#         sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
    "        return sentence_similarity_martix\n",
    "#     def create_graph(self, idx):\n",
    "#         \"\"\"Using word2vec cosine smilarity\"\"\"\n",
    "#         sentences_list = self.inputdata[idx]\n",
    "#         sentence_vectors = []\n",
    "#         for i in range(self.sent_num):\n",
    "#             if i < len(sentences_list):\n",
    "#                 s = sentences_list[i]\n",
    "#                 if len(s) != 0:\n",
    "#                     v = sum([word_embeddings.get(w, np.zeros((250,))) for w in s])/(len(s)+0.001)\n",
    "#                 else:\n",
    "#                     v = np.zeros((250,))\n",
    "#             else:\n",
    "#                 v = np.zeros((250,)) \n",
    "#             sentence_vectors.append(v)\n",
    "#         sentence_similarity_martix = np.eye(self.sent_num)\n",
    "#         for j in range(self.sent_num):\n",
    "#             for k in range(self.sent_num):\n",
    "#                 if j != k:\n",
    "#                     sentence_similarity_martix[j][k] = cosine_similarity(sentence_vectors[j].reshape(1,250), sentence_vectors[k].reshape(1,250))[0,0]\n",
    "\n",
    "# #         sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
    "#         return sentence_similarity_martix\n",
    "    \n",
    "    def create_lstm_embedding(self, data, idx):\n",
    "        doc_emb_array = LoadDocSentEmb(data, idx, self.sent_num)\n",
    "        hidden = (torch.randn(1, 1, 250), torch.randn(1, 1, 250))\n",
    "        doc_hidden = []\n",
    "        for i in doc_emb_array:\n",
    "            for j in i:\n",
    "                out, hidden = self.lstm(j.view(1, 1, -1), hidden)\n",
    "            doc_hidden.append(hidden[0])\n",
    "        return doc_hidden\n",
    "            \n",
    "    def create_gru_embedding(self, data, idx):\n",
    "        doc_emb_array = LoadDocSentEmb(data, idx, self.sent_num)\n",
    "        hidden = torch.randn(1, 1, 250)\n",
    "        doc_hidden = []\n",
    "        for i in doc_emb_array:\n",
    "            for j in i:\n",
    "                out, hidden = self.gru(j.view(1, 1, -1), hidden)\n",
    "            doc_hidden.append(hidden[0])\n",
    "        return doc_hidden\n",
    "    \n",
    "    def compute_rouge(self, input, gold, idx):\n",
    "        score_list = []\n",
    "        for sentence in input[idx]:\n",
    "            score = rouge.get_scores(gold[idx], [sentence])\n",
    "            score_list.append([score[0]['rouge-1']['r']])\n",
    "            if len(score_list) == self.sent_num:\n",
    "                break\n",
    "        if len(score_list) < self.sent_num:\n",
    "            while len(score_list) != self.sent_num:\n",
    "                score_list.append([0.0])\n",
    "        return score_list\n",
    "    \n",
    "    def trans_data(self, data):\n",
    "        trans = []\n",
    "        for sentences in data:\n",
    "            s_str = \"\"\n",
    "            for w in sentences:\n",
    "                s_str += w +' '\n",
    "            trans.append([s_str])\n",
    "        return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = GraphLoader('train','./').__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.28785527,  0.19549409,  0.44937891,  0.41897935,\n",
       "         0.30145866,  0.51115197, -0.06817409,  0.41364396,  0.07488795,\n",
       "         0.32580221,  0.18923962,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.28785527,  1.        ,  0.30073968,  0.39978355,  0.32332748,\n",
       "         0.36612588,  0.49933702, -0.13397253,  0.44358569,  0.05810773,\n",
       "         0.27528608,  0.09012038,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.19549409,  0.30073968,  1.        ,  0.37444597,  0.19789618,\n",
       "         0.36755693,  0.29125834,  0.18727028,  0.3235667 ,  0.04949016,\n",
       "         0.13395831,  0.1334742 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.44937891,  0.39978355,  0.37444597,  1.        ,  0.49535012,\n",
       "         0.38115534,  0.57205284, -0.10435088,  0.4393447 ,  0.28167656,\n",
       "         0.4778986 ,  0.31019366,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.41897935,  0.32332748,  0.19789618,  0.49535012,  1.        ,\n",
       "         0.44043803,  0.43795353, -0.09560066,  0.46824521,  0.1791549 ,\n",
       "         0.31878752,  0.43018514,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.30145866,  0.36612588,  0.36755693,  0.38115534,  0.44043803,\n",
       "         1.        ,  0.41321787,  0.15921345,  0.43991137,  0.10358692,\n",
       "         0.2228893 ,  0.390315  ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.51115197,  0.49933702,  0.29125834,  0.57205284,  0.43795353,\n",
       "         0.41321787,  1.        , -0.04856262,  0.46234044,  0.07856642,\n",
       "         0.40758592,  0.13514276,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-0.06817409, -0.13397253,  0.18727028, -0.10435088, -0.09560066,\n",
       "         0.15921345, -0.04856262,  1.        , -0.05005677, -0.0555483 ,\n",
       "        -0.1975202 ,  0.20619658,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.41364396,  0.44358569,  0.3235667 ,  0.4393447 ,  0.46824521,\n",
       "         0.43991137,  0.46234044, -0.05005677,  1.        ,  0.03388859,\n",
       "         0.27522653,  0.09135563,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.07488795,  0.05810773,  0.04949016,  0.28167656,  0.1791549 ,\n",
       "         0.10358692,  0.07856642, -0.0555483 ,  0.03388859,  1.        ,\n",
       "         0.44046021,  0.11727981,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.32580221,  0.27528608,  0.13395831,  0.4778986 ,  0.31878752,\n",
       "         0.2228893 ,  0.40758592, -0.1975202 ,  0.27522653,  0.44046021,\n",
       "         1.        ,  0.1899316 ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.18923962,  0.09012038,  0.1334742 ,  0.31019366,  0.43018514,\n",
       "         0.390315  ,  0.13514276,  0.20619658,  0.09135563,  0.11727981,\n",
       "         0.1899316 ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[-2.3633e-02, -2.3752e-01, -1.5863e-01,  2.2650e-01,  1.1861e-01,\n",
       "            9.5543e-02, -3.0530e-01,  1.3300e-01, -2.6690e-01,  1.5606e-01,\n",
       "            3.1622e-01,  2.1206e-01, -1.2966e-02,  2.5236e-02, -1.2698e-01,\n",
       "           -1.8631e-01,  8.1974e-02, -3.7372e-01,  6.3274e-02,  2.7741e-01,\n",
       "            1.6722e-01, -5.1829e-03,  1.7185e-01,  2.1024e-01, -3.2208e-01,\n",
       "            3.2513e-02, -4.1368e-02,  9.3692e-02, -4.7133e-02, -1.2692e-01,\n",
       "           -6.1206e-02, -2.5556e-01, -3.6455e-02,  6.4819e-02,  5.9680e-03,\n",
       "            1.6167e-01,  1.3276e-01, -1.2413e-01, -7.9466e-02,  2.7083e-01,\n",
       "            1.4911e-01,  2.2303e-01,  6.6630e-02,  3.1581e-02, -1.2163e-01,\n",
       "            1.4637e-01,  1.5481e-01, -3.8461e-02, -2.8159e-02,  1.2362e-02,\n",
       "            6.8382e-02,  1.1791e-01,  2.4305e-01, -1.0490e-01, -2.7647e-02,\n",
       "            2.4406e-01, -1.6569e-01,  2.9942e-02, -1.0270e-01,  1.6917e-01,\n",
       "            4.6042e-02,  1.0967e-01,  3.5491e-01,  1.2662e-01,  7.2565e-02,\n",
       "           -1.9437e-01, -6.7765e-02,  2.4672e-01, -1.4970e-01,  6.1395e-02,\n",
       "           -1.6172e-01, -1.7414e-01,  2.7340e-04, -4.5226e-01,  6.5025e-02,\n",
       "            1.3038e-01,  8.4570e-02, -8.8336e-02,  1.0888e-01, -7.1585e-02,\n",
       "            2.9723e-01, -8.1097e-02, -7.2185e-02, -5.9476e-02, -5.4973e-02,\n",
       "            1.8949e-01, -1.0391e-01, -4.0448e-02,  1.0503e-01, -1.3674e-01,\n",
       "           -8.9861e-02,  3.0921e-01,  8.6512e-02, -1.4028e-01,  2.8440e-01,\n",
       "           -2.4861e-01,  5.9456e-03, -1.7240e-01, -7.2253e-02, -1.4325e-01,\n",
       "           -8.2454e-02, -1.1681e-01, -3.1165e-02,  3.9017e-02,  1.7092e-01,\n",
       "            1.4062e-02, -2.8481e-01, -1.2100e-01,  1.1527e-02,  5.7446e-02,\n",
       "           -2.6093e-02, -1.2419e-01, -1.7128e-01, -1.0251e-01,  1.6747e-01,\n",
       "            9.1847e-02, -9.5705e-02,  1.7659e-01,  1.9279e-01,  2.8448e-01,\n",
       "            2.9712e-01,  2.4179e-01,  1.6203e-01,  2.8693e-01,  8.0741e-02,\n",
       "           -1.1140e-01, -1.9895e-02, -1.0442e-02,  2.7901e-01, -1.9243e-01,\n",
       "           -1.8880e-01, -2.6170e-01,  6.1771e-02, -1.2026e-01,  1.5703e-01,\n",
       "           -9.2939e-02, -7.7062e-02, -4.1444e-02, -8.6793e-02,  1.3424e-01,\n",
       "            2.0539e-01, -4.0213e-01,  2.8052e-01, -2.5685e-02,  1.5817e-01,\n",
       "            4.8633e-01,  1.6574e-01, -9.2482e-02, -9.7524e-02, -2.0896e-01,\n",
       "           -1.7560e-01,  2.7188e-02,  9.9640e-03, -3.3692e-02,  5.2213e-03,\n",
       "           -4.5273e-01,  1.2976e-01, -2.2742e-02,  2.0710e-01, -4.7448e-02,\n",
       "            5.4464e-02, -4.1172e-03,  1.1478e-01, -8.5563e-03,  1.8671e-01,\n",
       "            1.9620e-01,  2.2044e-01,  1.2921e-01,  1.2968e-01,  8.4460e-03,\n",
       "           -1.2832e-01,  2.3987e-01, -2.8135e-02, -1.4931e-01,  4.7119e-02,\n",
       "           -1.0408e-01,  1.1215e-01,  3.4471e-02, -8.3739e-04, -1.8832e-01,\n",
       "           -8.0472e-02,  1.0627e-01,  1.0854e-01,  1.5028e-01, -1.9651e-01,\n",
       "           -1.0334e-01, -2.9935e-01,  4.3343e-01, -5.0764e-02,  3.3065e-01,\n",
       "            1.5516e-01,  2.6026e-01,  1.2990e-01,  4.0533e-01, -1.0147e-01,\n",
       "            4.2288e-01,  9.8189e-02,  1.6866e-01, -3.1910e-02, -4.3354e-01,\n",
       "            1.7369e-02, -7.3129e-02,  3.9315e-02, -1.0480e-01, -3.3037e-01,\n",
       "            5.1692e-02,  3.2661e-01, -2.6458e-01, -2.1715e-01,  7.2474e-02,\n",
       "            1.1376e-01, -1.1796e-01,  8.2969e-02, -3.4531e-02, -2.7602e-01,\n",
       "           -9.7536e-02,  2.7896e-02, -3.0512e-02, -2.7864e-01, -1.4582e-01,\n",
       "           -3.6954e-01,  9.5681e-03,  2.1759e-01, -3.4530e-01,  1.4590e-01,\n",
       "           -2.6657e-01,  2.3855e-01,  4.9664e-01, -5.5479e-02, -6.8238e-02,\n",
       "           -2.1658e-03,  3.1276e-02, -5.9995e-02,  1.7351e-01, -1.1676e-01,\n",
       "            1.1792e-01,  4.8861e-02,  1.2219e-01, -2.5676e-02,  2.0830e-01,\n",
       "           -1.0154e-01,  1.1820e-01,  2.7357e-02,  9.6268e-02,  2.2450e-01,\n",
       "            8.8110e-02, -9.0008e-03,  1.6193e-01,  3.7684e-02, -7.7512e-02]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[ 0.1231,  0.0778, -0.1448, -0.1805, -0.2236,  0.0022, -0.1174,\n",
       "           -0.2171, -0.1311, -0.0495, -0.0064,  0.4697,  0.1470, -0.1289,\n",
       "            0.0260,  0.3864,  0.1554, -0.0555,  0.0088,  0.0254,  0.0777,\n",
       "            0.0229, -0.2655,  0.0734, -0.2095,  0.0263,  0.1839,  0.1175,\n",
       "           -0.0498, -0.0271,  0.0613, -0.2191,  0.0570, -0.0485,  0.0240,\n",
       "            0.0436,  0.2313,  0.1855,  0.0033, -0.0050, -0.2349,  0.0935,\n",
       "            0.1157,  0.2343, -0.0422,  0.1358,  0.2577,  0.0853,  0.0783,\n",
       "            0.2673,  0.1023, -0.0277, -0.0438,  0.0104,  0.0271,  0.0385,\n",
       "           -0.1767, -0.0424,  0.0686,  0.0085,  0.1128, -0.0833,  0.1107,\n",
       "           -0.2053, -0.0910,  0.0383, -0.2953, -0.0790, -0.1526, -0.0616,\n",
       "            0.1012,  0.1298, -0.0919, -0.0332,  0.1674,  0.1665,  0.1614,\n",
       "           -0.3092, -0.0073,  0.3677,  0.4935, -0.0742, -0.0632, -0.0061,\n",
       "            0.0079, -0.1457,  0.1052, -0.1419,  0.1750,  0.2761,  0.0821,\n",
       "            0.1461, -0.2596,  0.1690,  0.2713,  0.0671,  0.0717, -0.2733,\n",
       "           -0.0938, -0.0917,  0.0859, -0.1371, -0.3246,  0.1184,  0.0578,\n",
       "           -0.0333,  0.0375, -0.2366, -0.1838, -0.0595,  0.2017,  0.0523,\n",
       "            0.1684,  0.1098, -0.0469,  0.0941,  0.0239, -0.0466,  0.0029,\n",
       "            0.0231, -0.0607,  0.2013, -0.0623, -0.0522,  0.1234,  0.0879,\n",
       "           -0.1336, -0.4331,  0.3091, -0.0474, -0.2168,  0.1867,  0.0280,\n",
       "           -0.1311,  0.0013, -0.2560, -0.3308, -0.0029,  0.1230,  0.1262,\n",
       "            0.0404, -0.0137,  0.0531,  0.0722, -0.0907, -0.0478,  0.0185,\n",
       "           -0.0125, -0.0221, -0.1793, -0.2213, -0.1245, -0.1333,  0.0895,\n",
       "            0.1612, -0.1179, -0.0507, -0.0815, -0.1118,  0.1848, -0.0436,\n",
       "           -0.2463, -0.1780, -0.2802, -0.0098, -0.0100,  0.0973,  0.0525,\n",
       "           -0.2102,  0.0235,  0.0174,  0.0135, -0.0210, -0.1920,  0.0244,\n",
       "           -0.1066,  0.4355,  0.1534,  0.1086, -0.0384,  0.0207, -0.2300,\n",
       "            0.2817, -0.0165,  0.2902, -0.0181, -0.1806,  0.3596, -0.1777,\n",
       "           -0.0357, -0.0934, -0.0438,  0.2723, -0.0518, -0.1200,  0.0747,\n",
       "            0.2979,  0.1580,  0.1024, -0.3040, -0.1731,  0.2103,  0.0672,\n",
       "            0.2288, -0.3358, -0.0237, -0.0945,  0.0994,  0.0592,  0.0828,\n",
       "           -0.1807, -0.0036,  0.0873,  0.1134, -0.0618,  0.0876,  0.1649,\n",
       "           -0.0769,  0.0206,  0.0527,  0.1082,  0.0724,  0.0127,  0.1409,\n",
       "            0.0469, -0.0045,  0.0171,  0.0846,  0.3129, -0.0840, -0.0424,\n",
       "            0.0314,  0.1334,  0.0223, -0.1281, -0.1138,  0.1510,  0.1420,\n",
       "           -0.0964, -0.0791,  0.1743, -0.1456,  0.0553,  0.1884,  0.1157,\n",
       "            0.0578,  0.0240,  0.0432, -0.2273,  0.0561]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[ 6.0531e-02,  9.6729e-02, -8.4281e-03, -5.4930e-02, -2.9936e-01,\n",
       "           -1.0568e-01, -1.7455e-01, -1.4840e-02, -2.2040e-01,  6.9698e-02,\n",
       "            1.2072e-01,  9.9736e-02,  1.7060e-01,  5.8128e-03, -3.2423e-02,\n",
       "            4.4959e-02,  1.0778e-01, -1.8635e-01, -9.1049e-02,  1.9550e-01,\n",
       "            2.5294e-02, -6.2575e-02, -4.0207e-02,  1.6734e-01,  1.0458e-02,\n",
       "            1.2100e-01,  1.4545e-01,  1.3048e-01, -1.5034e-01, -8.3523e-02,\n",
       "            1.1730e-02, -1.7529e-01, -1.7659e-01, -1.4885e-01,  1.0584e-01,\n",
       "            1.4181e-01,  1.1965e-01, -1.0272e-01,  9.1512e-02,  7.6577e-02,\n",
       "            1.0394e-01,  9.2486e-02,  9.0877e-03,  9.3664e-02,  4.9671e-02,\n",
       "            6.2046e-02,  2.2854e-02,  1.2005e-01, -6.3673e-02,  1.2398e-04,\n",
       "           -1.9512e-03, -1.1497e-03,  3.6824e-02, -4.3986e-02, -1.9053e-03,\n",
       "            1.4719e-01, -5.0864e-02,  1.8201e-02,  2.0173e-01, -2.3787e-01,\n",
       "            2.6711e-02, -4.2938e-02,  2.8235e-01, -1.4533e-01, -1.7679e-01,\n",
       "           -2.2698e-01, -2.2248e-01, -8.0274e-02, -1.8963e-01, -7.5389e-02,\n",
       "            3.9569e-02, -4.5478e-02,  1.1401e-01, -1.9249e-01, -1.7205e-01,\n",
       "            5.5471e-02, -1.3495e-01, -9.4999e-02, -1.1721e-01,  2.1760e-01,\n",
       "            4.2785e-02,  2.8882e-02, -5.4803e-02,  1.4450e-01,  9.6352e-02,\n",
       "           -2.5146e-01,  4.3925e-02,  4.8942e-02,  9.7339e-02,  1.1414e-02,\n",
       "           -1.8371e-02,  5.3064e-02, -7.6292e-02,  1.6420e-01,  1.1585e-01,\n",
       "            1.4160e-02, -1.5246e-02, -2.5814e-02, -9.9571e-02, -2.1654e-02,\n",
       "            6.6587e-02,  1.6845e-01, -2.3997e-01,  1.5230e-01, -8.1822e-02,\n",
       "            9.0816e-02, -7.7766e-02, -1.2261e-02,  7.8083e-02,  1.2988e-01,\n",
       "           -1.2983e-01, -1.9971e-02,  2.5817e-02,  9.0419e-02,  9.9953e-02,\n",
       "            1.6203e-01, -1.1606e-01, -2.2899e-01,  1.1103e-01, -7.9975e-02,\n",
       "           -7.2059e-02,  5.5450e-02,  3.1513e-02, -6.0849e-02,  9.7150e-02,\n",
       "           -9.2095e-02,  9.3904e-02, -2.2249e-01,  1.5852e-01,  9.7007e-02,\n",
       "           -2.8274e-01,  2.0216e-02, -1.1244e-01, -1.0627e-01,  3.0581e-04,\n",
       "           -6.7641e-02, -6.3687e-02,  1.5109e-01,  5.6467e-02, -1.3325e-01,\n",
       "            1.1392e-01,  7.0687e-02, -4.8413e-02, -1.3436e-01,  4.9311e-02,\n",
       "            4.1225e-02, -1.4558e-01, -1.4083e-02, -1.5358e-01,  2.5738e-02,\n",
       "           -6.4765e-03, -1.0190e-01, -1.4121e-02,  1.7386e-02, -1.0272e-01,\n",
       "           -4.3284e-02, -1.3026e-01,  1.5288e-02, -9.6796e-02, -5.6371e-02,\n",
       "           -1.1395e-01, -1.0969e-01,  4.3643e-02, -4.9173e-02, -1.0885e-01,\n",
       "           -1.7247e-01,  1.2589e-01,  1.4915e-01,  1.7745e-01, -6.0708e-02,\n",
       "            1.5182e-01,  5.8981e-02, -1.2020e-03, -2.0805e-01,  9.2751e-02,\n",
       "           -1.1830e-01,  3.6938e-01,  1.0505e-01, -9.6795e-02, -2.0151e-02,\n",
       "           -7.6980e-02, -2.6115e-01,  2.4016e-01, -1.2562e-01,  1.9987e-01,\n",
       "           -1.3862e-02,  1.7997e-01,  2.1962e-01,  8.0960e-02,  9.1357e-02,\n",
       "           -1.4911e-01, -5.8268e-03,  1.2641e-01,  2.0935e-01, -9.5666e-02,\n",
       "           -3.5341e-02,  2.3598e-01,  5.6116e-04,  1.6524e-01,  2.3646e-03,\n",
       "           -7.1995e-02,  7.1863e-02, -1.8328e-02, -4.9168e-02, -1.4799e-01,\n",
       "            5.1700e-02,  6.3989e-02, -5.2617e-02,  1.2010e-01,  8.2351e-02,\n",
       "           -1.4253e-01,  5.8828e-02,  2.9132e-02,  9.7770e-02,  6.0840e-02,\n",
       "           -1.2655e-01,  3.2595e-01, -2.2872e-01, -2.0437e-01,  1.7827e-01,\n",
       "            2.9335e-01,  1.2868e-01, -1.1819e-02,  9.0459e-02, -5.9425e-02,\n",
       "           -9.2623e-03, -3.9401e-02,  2.0260e-01,  1.1252e-01,  1.7517e-01,\n",
       "            8.1799e-02, -4.0205e-02,  4.2378e-02, -8.1041e-02, -1.0917e-01,\n",
       "           -2.6150e-02, -1.9437e-01, -4.1617e-02, -2.8031e-02,  4.8454e-02,\n",
       "            1.0973e-01,  1.1507e-01,  8.4830e-02,  7.2228e-02,  9.3254e-02,\n",
       "           -1.1208e-01,  1.6809e-01, -6.3730e-02, -4.5299e-02, -6.4907e-02]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[ 1.0416e-01,  2.0687e-01, -1.8321e-01, -2.6022e-01, -1.0598e-01,\n",
       "           -7.6736e-02,  1.2884e-02,  4.4527e-02,  5.1165e-02, -3.4571e-04,\n",
       "            2.0673e-01,  1.0216e-01,  2.3780e-01, -2.2784e-02, -6.6051e-02,\n",
       "            1.5560e-01,  6.8461e-02, -5.1996e-01,  1.0192e-01,  1.0311e-01,\n",
       "           -9.5260e-02,  2.2439e-02,  1.8986e-01, -1.1273e-01,  6.0931e-02,\n",
       "           -2.6018e-02,  8.6594e-02,  1.3308e-01, -1.3687e-01,  1.9549e-01,\n",
       "            3.7441e-02, -3.0766e-01,  2.2172e-01,  1.2673e-01, -6.5736e-02,\n",
       "            9.5235e-02,  2.0312e-01,  1.5403e-01,  4.7273e-02,  5.2065e-02,\n",
       "            1.4599e-01,  6.4335e-02,  3.5093e-01,  2.3041e-01, -8.8593e-02,\n",
       "           -1.2056e-01, -1.3141e-01,  2.3839e-01,  2.4919e-02,  2.6411e-01,\n",
       "           -1.4803e-01,  1.6143e-01,  2.5708e-01, -7.3119e-02, -2.9547e-01,\n",
       "            1.7124e-01,  1.9080e-01, -7.8937e-02,  6.2073e-02, -1.0445e-01,\n",
       "            2.8373e-01,  4.6779e-02, -6.0432e-02, -1.2706e-01,  3.0994e-03,\n",
       "           -1.4129e-01, -1.0613e-01,  1.0967e-02, -1.5582e-01, -1.0723e-01,\n",
       "            2.3677e-01,  8.9750e-02,  2.1738e-01, -3.3151e-01,  1.8760e-01,\n",
       "           -2.1562e-01,  4.2012e-02, -1.9408e-01, -1.4297e-01,  4.6140e-01,\n",
       "           -2.7934e-01, -2.0474e-01, -1.1903e-01,  2.7940e-01, -1.9158e-01,\n",
       "           -1.6500e-02, -3.1387e-02, -1.7225e-02, -1.1481e-01,  1.7911e-02,\n",
       "            1.1755e-02, -9.0255e-02,  1.0663e-01, -1.3006e-01,  1.9424e-01,\n",
       "            3.7438e-02,  2.0469e-01, -1.6302e-01,  1.8889e-01, -1.3052e-01,\n",
       "            1.1198e-01, -3.2621e-02, -2.3061e-01,  1.3680e-01, -2.5377e-02,\n",
       "           -4.4639e-03, -2.4002e-01, -4.3531e-02, -1.1874e-01, -2.2019e-03,\n",
       "            2.1318e-01, -1.7435e-01,  1.2423e-01,  1.0284e-01, -5.1439e-02,\n",
       "           -6.8506e-02, -1.2279e-01,  4.2428e-02, -7.6856e-02,  1.5754e-02,\n",
       "           -5.0888e-02, -7.6620e-02,  1.9017e-02,  3.5608e-02,  7.8268e-02,\n",
       "           -2.1701e-01, -1.2730e-01, -2.6592e-01,  2.4971e-01,  1.8474e-02,\n",
       "           -1.9943e-01,  1.5796e-01,  3.3772e-02, -1.0631e-01, -1.8589e-01,\n",
       "           -1.4240e-01, -1.8062e-01,  5.8671e-02,  2.5978e-01, -4.3584e-02,\n",
       "            1.7799e-01,  6.9562e-02, -3.7625e-01,  7.0187e-02, -5.6904e-03,\n",
       "            1.0075e-01,  3.4379e-03,  4.3554e-02, -3.3914e-02, -1.9812e-02,\n",
       "           -1.6457e-01, -5.9036e-02, -1.3172e-01,  2.0893e-01, -7.8216e-02,\n",
       "            1.8265e-01, -1.8752e-01,  5.3679e-02, -1.8257e-01,  1.1953e-01,\n",
       "           -1.5483e-01,  1.2990e-02, -1.3372e-01, -2.3137e-01, -2.9307e-01,\n",
       "           -3.3158e-01, -3.0595e-01,  2.7897e-01,  1.8555e-01, -2.2205e-02,\n",
       "            1.3208e-01,  9.0585e-03,  3.3281e-03, -2.1493e-01,  7.5637e-02,\n",
       "           -1.6150e-01,  2.4336e-01,  1.4269e-01,  9.0281e-02, -3.8077e-02,\n",
       "            3.0199e-02, -3.6961e-01,  1.5230e-01, -1.5995e-01, -4.8667e-02,\n",
       "           -2.5938e-02, -4.3146e-02,  2.1191e-01, -2.1190e-01, -1.6197e-01,\n",
       "           -2.4484e-01,  8.5023e-02,  7.2922e-02,  5.3869e-02,  1.8398e-01,\n",
       "            6.6787e-02,  9.0516e-02,  5.1131e-02, -6.9340e-03, -2.5213e-01,\n",
       "           -1.8218e-01,  2.0529e-01, -6.8451e-02,  1.8943e-01, -1.5467e-02,\n",
       "            1.2688e-01,  1.7525e-03,  4.5048e-02, -1.4537e-01,  1.6752e-01,\n",
       "            1.7786e-01,  1.2302e-02,  1.9735e-01,  1.3482e-01,  1.7884e-01,\n",
       "           -2.0226e-01,  3.5341e-02, -2.4863e-02, -2.1691e-02,  2.7239e-01,\n",
       "            2.2177e-01,  1.5495e-01, -1.8685e-01, -2.0462e-01,  2.0212e-02,\n",
       "           -1.1408e-01,  3.4644e-02,  1.6967e-01,  2.9307e-01, -4.8267e-02,\n",
       "           -1.0173e-01,  9.4838e-02,  1.6710e-02, -1.0203e-01,  1.4119e-01,\n",
       "           -7.0068e-02,  1.8391e-01, -5.9349e-02,  6.1513e-03,  3.1284e-02,\n",
       "            4.0525e-02, -1.1919e-01, -1.8194e-02, -7.9623e-02, -5.4015e-02,\n",
       "            1.9735e-01,  2.6236e-01, -1.2615e-02, -4.8930e-02,  1.0974e-01]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[-0.2768,  0.0029, -0.2334, -0.1924, -0.1969,  0.1118, -0.1331,\n",
       "            0.3208, -0.3318,  0.2713, -0.4062,  0.0924,  0.1929, -0.1850,\n",
       "           -0.0800,  0.0988,  0.4192, -0.1311,  0.0820,  0.0018, -0.0355,\n",
       "            0.2173,  0.0780, -0.0104,  0.0626,  0.0494, -0.1400, -0.0247,\n",
       "           -0.2491,  0.3353,  0.2044, -0.1281,  0.2066,  0.0547,  0.1169,\n",
       "            0.0645,  0.0924,  0.2002, -0.2276,  0.0931, -0.0607,  0.0201,\n",
       "            0.0549, -0.3700, -0.2080,  0.0050,  0.2303,  0.1224, -0.0041,\n",
       "            0.0222, -0.1334, -0.3423,  0.3556,  0.0729, -0.2814, -0.0729,\n",
       "           -0.3723, -0.0302, -0.0719,  0.4819,  0.0450,  0.1225,  0.0469,\n",
       "           -0.2790,  0.0890,  0.2197,  0.2373,  0.3782, -0.2478, -0.1262,\n",
       "            0.3658, -0.1054, -0.1607, -0.0750,  0.3423, -0.1157,  0.1322,\n",
       "           -0.0449,  0.1460,  0.2104,  0.1218,  0.2247, -0.1259,  0.0142,\n",
       "           -0.4614, -0.1143, -0.0143, -0.0711, -0.0942,  0.0617, -0.0750,\n",
       "            0.0460, -0.0298,  0.3262,  0.3258, -0.2633,  0.0278, -0.4578,\n",
       "           -0.0223, -0.0255,  0.2618, -0.1498, -0.1352,  0.1422,  0.1568,\n",
       "           -0.1277, -0.0429, -0.0901,  0.0390,  0.1800,  0.0792, -0.2340,\n",
       "           -0.2920,  0.1863,  0.1601, -0.1324, -0.2704,  0.3116,  0.0732,\n",
       "            0.3520, -0.0305, -0.1577,  0.0520,  0.2798, -0.2735, -0.1587,\n",
       "           -0.1489, -0.1984, -0.1357, -0.1456, -0.1219,  0.0518,  0.0268,\n",
       "           -0.2911, -0.0686,  0.1633,  0.0264, -0.2034,  0.2838, -0.1698,\n",
       "            0.1287, -0.2333,  0.0373, -0.0241, -0.0058,  0.4991,  0.1268,\n",
       "            0.1740, -0.1403,  0.0057, -0.0752,  0.2689, -0.0244,  0.3038,\n",
       "           -0.0079,  0.2206,  0.1657, -0.1682, -0.0887,  0.2833, -0.1812,\n",
       "            0.1926, -0.0868, -0.1836, -0.3727, -0.0828, -0.2209,  0.1519,\n",
       "           -0.0258, -0.2237, -0.0167, -0.0779,  0.1949, -0.0875,  0.0121,\n",
       "           -0.1277,  0.1482, -0.1944,  0.1030, -0.0890,  0.2341, -0.0337,\n",
       "           -0.0199, -0.0446, -0.0175, -0.1393, -0.0550,  0.4149,  0.2426,\n",
       "           -0.1298,  0.2135,  0.1376, -0.2267, -0.0483, -0.1397,  0.1909,\n",
       "            0.2469,  0.0890,  0.1265,  0.0395, -0.2444,  0.3550, -0.0447,\n",
       "           -0.1381, -0.1772, -0.0286, -0.2127,  0.3001, -0.0254,  0.0929,\n",
       "            0.1379, -0.0048,  0.0990,  0.0556,  0.1704,  0.2141, -0.0614,\n",
       "            0.0024, -0.0007,  0.0628,  0.4224, -0.1540,  0.1460,  0.0831,\n",
       "            0.1363,  0.0398,  0.2316, -0.1240, -0.5383, -0.4189,  0.0785,\n",
       "            0.2450,  0.0598,  0.2184, -0.0446,  0.0462, -0.0323, -0.0019,\n",
       "           -0.0442,  0.0935, -0.0709, -0.0844, -0.0485,  0.2545,  0.1347,\n",
       "            0.1292, -0.1122,  0.3321, -0.0643, -0.1991]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[ 1.1439e-01, -1.6504e-01, -1.4048e-01, -3.4032e-02, -5.9386e-02,\n",
       "            4.4951e-02, -4.1033e-01,  3.0054e-01, -2.7754e-01,  2.4071e-01,\n",
       "            5.0077e-01,  2.5446e-01,  2.0874e-01,  2.2849e-01, -1.7275e-03,\n",
       "           -1.0050e-01,  3.1423e-02, -1.0946e-01, -3.2368e-01,  1.7663e-01,\n",
       "            2.8150e-01, -6.2355e-02, -1.4124e-02, -2.5625e-01,  2.5027e-02,\n",
       "            2.4382e-01,  1.5183e-01,  1.4569e-01, -1.9706e-01,  4.9777e-01,\n",
       "           -8.5376e-02,  1.0341e-01,  3.2147e-01,  7.9130e-02,  4.3253e-02,\n",
       "            4.9882e-02,  4.1991e-01,  8.9660e-02, -3.9089e-02, -1.2333e-01,\n",
       "            1.9967e-01,  3.2511e-02, -1.1163e-01, -2.6599e-02, -3.6433e-02,\n",
       "           -3.0168e-01, -7.9517e-03,  7.0537e-02,  9.0320e-02,  1.8509e-01,\n",
       "            1.7117e-01,  8.3038e-02,  3.4258e-01, -1.3335e-02, -3.5808e-01,\n",
       "            2.0880e-01,  1.9097e-01, -9.6060e-02,  1.4410e-01, -7.9736e-02,\n",
       "            1.4323e-01,  6.4278e-02,  3.1489e-02, -3.2322e-01,  6.5351e-02,\n",
       "           -2.3226e-01, -8.7443e-02,  3.9816e-02,  1.5207e-01, -3.1201e-01,\n",
       "            6.2178e-03,  4.1050e-02, -3.3776e-02, -2.0360e-01, -1.6994e-02,\n",
       "           -2.2333e-01, -1.9644e-02, -1.8790e-01,  1.9867e-02, -3.5187e-02,\n",
       "            1.0875e-01, -3.4375e-02,  4.7332e-02,  2.3539e-01,  3.1790e-01,\n",
       "            1.7222e-02,  1.6139e-01, -2.7232e-02, -3.6920e-03, -3.8185e-01,\n",
       "            5.6195e-02,  5.7664e-02,  1.2599e-01, -1.0243e-01,  1.6915e-01,\n",
       "           -3.8071e-01,  2.7110e-01,  6.8859e-03,  1.2954e-04, -1.7167e-01,\n",
       "            2.2893e-01, -1.1270e-01,  1.7421e-02,  3.5069e-02,  2.1585e-01,\n",
       "            8.9660e-04, -2.3972e-01,  1.6753e-01,  1.9523e-01,  1.8238e-01,\n",
       "           -1.1984e-01,  2.1235e-02, -1.2358e-01,  1.1352e-01,  6.5329e-02,\n",
       "           -4.8044e-02, -3.2457e-01,  1.3020e-01,  5.7579e-02,  1.7736e-01,\n",
       "           -2.7914e-01,  2.1099e-01,  2.8185e-01,  3.5814e-02, -1.9235e-01,\n",
       "           -2.8754e-02,  4.3176e-02, -1.3853e-01, -3.2546e-01, -1.7875e-01,\n",
       "            7.0661e-03, -1.6417e-01,  1.2897e-01, -3.3603e-03, -1.2611e-01,\n",
       "            5.6163e-02,  1.1172e-02, -1.9595e-01,  1.0613e-01,  2.0694e-03,\n",
       "            9.7909e-02, -2.0634e-01,  6.0363e-03, -1.7385e-01, -7.0377e-02,\n",
       "            1.9042e-01,  8.3553e-02,  1.0580e-03, -1.8136e-01, -1.8590e-01,\n",
       "           -2.8634e-01,  2.2966e-01,  1.5708e-01,  9.6217e-02, -1.1782e-01,\n",
       "           -1.2179e-01, -8.5011e-02,  6.9635e-02, -7.5236e-02,  9.4807e-02,\n",
       "           -1.6665e-01,  1.9526e-01, -1.5601e-02, -1.0207e-01, -9.9162e-02,\n",
       "           -2.5821e-01,  2.6719e-01,  2.3230e-01, -3.2640e-02,  2.6345e-02,\n",
       "            8.3772e-02,  2.1472e-01,  1.4425e-01, -1.3903e-01,  1.3746e-01,\n",
       "           -2.7865e-02,  3.7100e-02,  1.6060e-01,  2.6657e-01, -2.3002e-01,\n",
       "           -1.4565e-02, -2.4521e-01,  7.7498e-02, -2.8979e-02, -4.5804e-01,\n",
       "           -6.7634e-02,  3.7059e-02,  1.7083e-01,  8.1129e-02,  8.9545e-02,\n",
       "           -1.4251e-01, -1.8654e-01,  1.4249e-01, -1.0087e-01, -2.8577e-01,\n",
       "            1.8544e-01,  3.3313e-03,  1.4379e-01, -1.3319e-01, -9.0003e-02,\n",
       "           -2.4396e-01, -3.5086e-02, -2.8504e-01, -2.5345e-01, -1.5704e-01,\n",
       "           -1.0636e-01,  3.3633e-01, -5.6085e-02, -4.3182e-02,  3.2731e-01,\n",
       "           -2.7276e-01, -7.0690e-02,  1.8241e-01, -7.4929e-02,  2.2631e-01,\n",
       "            1.1282e-01, -7.8020e-02, -3.2294e-01,  1.0117e-01, -2.0893e-01,\n",
       "           -2.2612e-01,  1.7380e-01,  5.4134e-02, -3.1715e-01,  1.6352e-01,\n",
       "           -1.8739e-01,  2.4523e-01,  3.7864e-01, -4.2235e-01,  4.4753e-02,\n",
       "           -1.5101e-01,  4.9073e-02,  3.0784e-01, -1.7135e-01,  8.5772e-02,\n",
       "            1.4555e-01,  1.1212e-01, -1.2387e-01,  4.5574e-01,  2.8140e-01,\n",
       "           -2.5973e-01,  2.7046e-02,  1.7090e-01,  1.0835e-01,  1.7009e-01,\n",
       "            2.2795e-01,  1.8835e-01,  3.1979e-01,  3.8044e-01,  2.5412e-01]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[-4.3519e-01,  1.0475e-01, -2.5247e-01,  1.1549e-01, -7.1346e-02,\n",
       "           -3.3000e-02, -3.2497e-01,  2.7733e-01, -3.2961e-01, -2.1101e-04,\n",
       "           -7.2605e-02,  4.8763e-02,  4.4344e-02, -1.9075e-02,  8.5473e-02,\n",
       "           -8.7591e-02,  1.8225e-01, -1.2706e-01,  1.5581e-01, -1.5932e-02,\n",
       "           -5.5449e-02, -1.8746e-01,  2.4429e-01, -3.0421e-01,  6.3840e-02,\n",
       "            9.9071e-02,  2.3120e-01,  6.4776e-02, -3.7657e-01,  8.4412e-02,\n",
       "            1.6475e-01, -2.2938e-01,  2.4186e-01, -1.8971e-01,  1.2624e-01,\n",
       "            1.7008e-01,  1.6782e-01, -2.0056e-01, -2.0399e-01, -9.9845e-02,\n",
       "            4.4239e-01,  1.0381e-01, -7.8792e-02, -2.3140e-01, -1.9539e-01,\n",
       "           -1.8336e-01,  1.5388e-01, -9.7791e-03, -3.2240e-01, -1.8774e-01,\n",
       "            1.4185e-01,  1.1396e-01,  1.5449e-02,  9.5068e-02, -1.4559e-01,\n",
       "           -4.9384e-02, -1.4489e-01,  4.4270e-02,  3.0587e-01, -2.9189e-01,\n",
       "            1.1697e-01,  1.1863e-01, -1.3691e-01, -1.2139e-01,  6.5623e-02,\n",
       "           -8.0089e-02, -9.4075e-03,  3.9400e-02, -1.9412e-02, -2.8841e-01,\n",
       "            1.2343e-01,  3.2355e-01,  1.9161e-01, -1.8047e-01, -1.0171e-01,\n",
       "            1.5145e-01, -1.9401e-01, -5.1129e-02,  2.4546e-02,  2.8021e-02,\n",
       "            1.2713e-01, -1.2525e-04, -1.3261e-01, -1.4416e-01, -1.0031e-01,\n",
       "           -1.7432e-01,  1.9744e-01,  2.9867e-01, -1.2765e-01, -3.2613e-02,\n",
       "           -9.6149e-03,  3.2366e-01, -2.4682e-03,  1.0805e-01,  8.5642e-03,\n",
       "           -1.6984e-01,  2.6397e-01, -7.5699e-02,  2.4241e-01, -2.0618e-01,\n",
       "            1.7183e-01, -2.7049e-01, -9.9783e-02,  3.6051e-01, -5.3781e-02,\n",
       "           -1.0462e-01,  5.3562e-02,  1.4060e-02,  2.5502e-03,  1.3946e-01,\n",
       "            5.0486e-02, -3.8534e-01, -1.4367e-01, -7.5281e-02,  1.3645e-01,\n",
       "           -4.3241e-02, -1.3130e-01, -2.6723e-01, -1.4927e-02,  9.5197e-02,\n",
       "           -2.4139e-01, -1.2300e-01,  1.6161e-01,  2.7823e-02, -1.3151e-01,\n",
       "           -3.0206e-01, -4.9833e-02, -9.0295e-02, -7.0174e-02,  2.1459e-01,\n",
       "           -3.2436e-02,  1.2784e-01,  1.1081e-01,  2.4599e-02, -1.1259e-01,\n",
       "           -5.0816e-02, -1.9507e-01, -1.6673e-01, -9.6649e-03, -7.4623e-02,\n",
       "            1.1414e-01, -5.4604e-02,  2.2231e-02, -3.0837e-02, -3.1760e-02,\n",
       "            4.1001e-01,  7.4949e-02,  4.0598e-02, -8.1451e-02, -5.8196e-02,\n",
       "           -1.9085e-01, -9.2355e-02,  8.0603e-02, -2.0924e-01,  1.0585e-02,\n",
       "            5.1854e-02, -1.4220e-02, -1.6786e-02, -1.3759e-01,  2.1482e-01,\n",
       "           -1.3375e-01,  1.2585e-01, -2.9706e-02, -1.5424e-02, -2.2022e-01,\n",
       "            2.0076e-01, -1.2331e-01,  1.2221e-01,  2.6016e-01,  1.5311e-01,\n",
       "           -1.2611e-01, -5.3810e-02,  2.3844e-01, -1.0584e-01,  6.8607e-02,\n",
       "            7.7560e-02,  1.8392e-01,  5.1863e-02,  7.8489e-02, -1.3490e-01,\n",
       "            1.9712e-01,  2.0084e-02, -2.8077e-02,  1.5618e-02, -1.7184e-01,\n",
       "           -1.0281e-01,  9.4926e-02,  5.4203e-01,  6.6143e-02, -3.5775e-01,\n",
       "            4.2936e-02, -8.2442e-03,  7.5475e-02,  1.2130e-01,  1.0563e-02,\n",
       "           -3.3754e-02,  1.1436e-01,  1.3189e-01,  3.7268e-02, -1.9759e-01,\n",
       "           -2.5310e-01,  5.7063e-02, -1.2046e-01,  6.8826e-03, -7.4720e-02,\n",
       "           -2.2864e-01,  1.5268e-01, -1.8808e-01,  8.4128e-02,  1.5547e-01,\n",
       "            2.9485e-01,  3.1521e-02,  2.0720e-01,  5.5843e-02, -1.1463e-02,\n",
       "            5.5801e-02, -2.8182e-02, -9.0968e-02,  4.3715e-02,  1.1285e-02,\n",
       "            5.5726e-01,  7.1206e-03,  3.2077e-01, -2.3380e-02,  4.3146e-02,\n",
       "           -3.3808e-01,  4.5872e-02,  1.0241e-01, -3.4260e-01,  9.0457e-02,\n",
       "           -3.0604e-01,  2.9199e-02,  1.4689e-01,  8.1477e-04,  1.5735e-01,\n",
       "            3.2017e-01,  7.4717e-02, -1.0548e-01, -3.0208e-03,  1.4899e-01,\n",
       "            2.1677e-01, -1.5155e-01,  2.1667e-01,  2.6047e-01, -1.2831e-02,\n",
       "            1.6759e-01, -3.1223e-01,  4.1754e-02,  1.0044e-01,  2.4122e-01]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[ 6.2049e-02,  1.0016e-01,  3.8922e-02, -1.5507e-02, -2.4921e-01,\n",
       "           -6.2603e-02, -1.2545e-01, -6.6255e-03, -2.7537e-01,  4.7930e-02,\n",
       "            1.4802e-01,  1.0650e-01,  2.0603e-01,  2.0596e-02, -5.1522e-02,\n",
       "            1.0685e-01,  3.3968e-02, -2.0869e-01, -1.2806e-01,  1.8854e-01,\n",
       "           -2.7101e-02, -3.0581e-02,  2.2283e-04,  1.9280e-01,  2.7429e-02,\n",
       "            7.9294e-02,  1.9104e-01,  1.7167e-01, -8.7387e-02, -2.5999e-02,\n",
       "            8.3789e-02, -2.1200e-01, -8.4096e-02, -2.2496e-01,  1.0451e-01,\n",
       "            1.0846e-01,  6.3121e-02, -1.5686e-01,  1.3176e-01,  1.4959e-01,\n",
       "            1.3198e-01,  1.1463e-01,  7.3150e-02,  1.3139e-01, -4.3454e-03,\n",
       "           -6.7953e-02,  8.0575e-02,  1.6425e-01, -7.9361e-02,  2.2032e-02,\n",
       "            1.4709e-01, -7.4304e-02, -4.1258e-04, -1.1340e-01, -5.5587e-02,\n",
       "            1.6622e-01,  3.9763e-02,  3.9803e-02,  1.7690e-01, -2.3900e-01,\n",
       "            3.8508e-02, -6.9491e-02,  3.0148e-01, -1.6337e-01, -2.1410e-01,\n",
       "           -1.9160e-01, -2.3148e-01,  2.0558e-02, -2.3489e-01, -1.3457e-01,\n",
       "           -2.1034e-02,  1.3648e-01,  1.5195e-01, -2.2350e-01, -9.0546e-02,\n",
       "            1.2382e-01, -1.6342e-01, -1.0332e-01, -1.2562e-01,  2.1915e-01,\n",
       "            5.1929e-02, -7.1144e-02, -6.4729e-02,  1.8301e-01,  3.2276e-02,\n",
       "           -2.4870e-01,  3.9591e-02,  5.0728e-02,  1.0868e-01,  6.4170e-02,\n",
       "           -9.4805e-02,  1.0756e-01, -8.0274e-02,  4.2031e-02,  9.9094e-02,\n",
       "            4.0580e-02,  6.1142e-02,  8.1164e-02, -1.2001e-01,  1.0861e-01,\n",
       "            6.6237e-02,  1.4223e-01, -2.9463e-01,  1.9648e-01,  5.5371e-02,\n",
       "            1.2163e-01, -1.6030e-01, -3.1522e-02, -1.6881e-02, -3.7882e-02,\n",
       "           -1.1727e-01,  3.4217e-02,  1.5071e-01,  2.5415e-02,  9.4762e-02,\n",
       "            1.4941e-01, -9.2100e-02, -1.5565e-01,  5.6941e-02, -1.0112e-01,\n",
       "           -1.8865e-01, -1.0461e-01, -6.1799e-02, -6.7197e-02,  1.1995e-01,\n",
       "           -1.9507e-02,  8.0083e-02, -2.4572e-01,  1.1823e-01, -4.9284e-02,\n",
       "           -1.0951e-01,  7.3939e-02, -8.0648e-02, -1.3940e-01, -2.2679e-02,\n",
       "           -7.7112e-02, -6.6486e-02,  3.1842e-01,  8.3688e-02, -1.1669e-01,\n",
       "            8.2892e-02,  9.1391e-02,  7.7039e-03, -1.5766e-01,  1.6460e-01,\n",
       "            8.5231e-03, -2.4132e-01, -3.6797e-02, -2.4028e-01,  7.4585e-02,\n",
       "            1.3272e-02, -1.3155e-01, -9.2461e-02,  4.8861e-02, -1.2391e-01,\n",
       "            9.4755e-02, -9.9261e-02,  1.2119e-01, -1.2304e-01,  1.0281e-01,\n",
       "           -1.1741e-01, -9.6960e-02,  9.1223e-02, -7.3959e-02, -1.3085e-01,\n",
       "           -2.1062e-01,  1.1526e-01,  1.3215e-01,  1.0735e-01, -1.2338e-01,\n",
       "            2.1056e-01,  2.3445e-02,  2.2579e-02, -4.2239e-01,  9.9727e-02,\n",
       "           -1.5122e-01,  3.4449e-01,  9.0509e-02, -1.4541e-01,  2.8981e-02,\n",
       "           -1.6161e-01, -2.4823e-01,  2.6791e-01, -1.3765e-01,  1.6025e-01,\n",
       "           -6.9899e-02,  1.6331e-01,  1.8246e-01,  2.8103e-02,  1.0719e-01,\n",
       "           -2.6239e-01,  2.6440e-02,  1.2803e-01,  2.2958e-01, -1.1746e-01,\n",
       "            1.2521e-02,  2.3142e-01,  1.7201e-02,  1.3824e-01,  6.1571e-02,\n",
       "           -1.7551e-01,  4.4370e-02, -8.9780e-02, -2.4336e-02, -3.1033e-01,\n",
       "           -2.9148e-02,  3.6319e-02, -1.1582e-01,  1.0845e-01,  3.0764e-01,\n",
       "           -2.3332e-01,  9.4012e-02,  4.2400e-02,  1.2822e-01, -2.9494e-01,\n",
       "           -8.2487e-02,  3.0853e-01, -1.6770e-01, -1.3452e-01,  2.0070e-01,\n",
       "            2.4080e-01,  1.9913e-01, -8.8843e-02,  7.6318e-02, -3.1556e-02,\n",
       "           -2.9887e-02, -1.3774e-01,  1.3957e-01,  2.5325e-01,  9.2905e-02,\n",
       "           -5.4241e-04, -9.9340e-02,  6.2394e-02, -8.2351e-02, -1.2532e-01,\n",
       "           -5.6324e-02, -2.0660e-01, -3.3117e-02, -1.4171e-01, -3.6986e-02,\n",
       "            1.0348e-01,  9.9591e-02,  1.3619e-02,  5.9785e-02,  1.0480e-01,\n",
       "           -1.5193e-01,  2.5074e-01, -3.5163e-02,  8.9054e-02, -7.5450e-02]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[ 9.4824e-02,  9.6877e-02,  1.3681e-01, -1.7954e-01, -1.1785e-01,\n",
       "            4.1094e-03, -8.0190e-02, -7.7177e-03,  1.0865e-02,  1.5494e-01,\n",
       "            1.0437e-01,  1.0752e-01,  1.2589e-01, -1.0649e-01, -4.4471e-02,\n",
       "           -1.2123e-01,  1.1173e-01, -1.9004e-01,  2.1766e-02,  1.7194e-01,\n",
       "            1.1582e-01, -1.6466e-01,  3.3559e-01,  3.5107e-01,  9.3285e-02,\n",
       "            1.0932e-01,  9.1166e-02,  8.4832e-02, -2.0851e-01,  2.4105e-02,\n",
       "           -2.2037e-02, -4.4622e-02, -2.4535e-01, -6.4173e-02, -1.3079e-01,\n",
       "           -3.6919e-02, -6.4058e-02, -6.2815e-02,  2.9581e-02,  5.7754e-02,\n",
       "           -6.5385e-02,  2.8684e-01,  8.3163e-02,  5.4322e-02, -2.4808e-01,\n",
       "           -1.6996e-01, -1.0224e-01, -8.1503e-02, -1.1547e-01,  7.6685e-03,\n",
       "           -9.4391e-02,  3.7844e-02,  9.1667e-02, -2.1887e-01,  3.8154e-02,\n",
       "            1.9640e-01,  7.2563e-02,  2.6059e-02, -2.1714e-02, -1.8994e-01,\n",
       "            3.8064e-02, -2.0885e-01,  1.2334e-02, -1.5657e-01,  4.2301e-02,\n",
       "           -7.0833e-02, -5.1442e-02, -1.1164e-01,  8.4677e-02, -1.9507e-01,\n",
       "           -5.3779e-02,  7.7197e-02,  2.3570e-02, -7.5723e-02, -6.7424e-02,\n",
       "           -2.1355e-02, -2.1479e-01,  8.9276e-02, -6.7340e-02, -2.1786e-02,\n",
       "           -2.8344e-02,  9.7849e-03, -4.2245e-02,  2.6221e-02, -7.7477e-02,\n",
       "           -8.6680e-02,  9.2493e-02, -2.6433e-02,  8.3506e-03,  2.6786e-02,\n",
       "           -1.4949e-01,  1.9410e-01,  1.3323e-01,  8.1519e-02,  1.3729e-02,\n",
       "            4.2181e-02,  1.2542e-01,  5.9412e-02,  8.2520e-02,  1.9857e-01,\n",
       "            2.8324e-02,  7.5771e-02,  1.5042e-01,  2.7200e-01,  1.0057e-01,\n",
       "            1.8141e-01,  1.8925e-01,  1.2574e-01,  8.4143e-02,  2.1339e-01,\n",
       "           -1.2340e-01, -1.0430e-01,  1.2305e-02,  1.4640e-01,  1.2005e-01,\n",
       "            2.3461e-01, -3.6791e-02,  1.1044e-01, -3.9477e-02,  2.6975e-01,\n",
       "            1.5546e-01, -1.3290e-02,  1.6767e-01,  1.4585e-01, -3.6587e-02,\n",
       "            1.0529e-02, -1.9246e-01,  4.6865e-02,  2.4821e-01,  1.2352e-01,\n",
       "            2.8559e-02, -5.5340e-02, -3.5889e-01,  2.2700e-02,  1.7795e-01,\n",
       "           -3.0984e-02, -1.8639e-01, -1.1418e-01, -1.0131e-01, -2.1165e-02,\n",
       "            4.4330e-02, -2.9063e-02, -9.3532e-02,  2.4668e-02,  1.2615e-01,\n",
       "            1.4715e-01,  7.6615e-03, -1.2538e-01, -6.3743e-02, -3.0864e-03,\n",
       "           -1.0047e-01,  6.2156e-02,  2.5830e-01, -4.6112e-02, -1.6258e-01,\n",
       "            2.0057e-01,  1.0420e-01,  1.4456e-01, -5.5306e-02,  1.5086e-01,\n",
       "            4.7587e-02,  9.7663e-02, -3.2749e-02, -1.8960e-01,  7.6738e-02,\n",
       "           -2.0345e-01, -8.2812e-02,  1.2959e-01,  5.9152e-02, -3.1068e-01,\n",
       "            1.5000e-01,  1.0092e-01,  7.4903e-02,  5.8535e-02, -1.4067e-01,\n",
       "           -2.6197e-01, -2.0785e-01,  4.0558e-02, -8.1260e-03,  1.3760e-01,\n",
       "            7.5984e-02, -8.3672e-04,  2.0827e-02,  2.1571e-02, -8.6283e-02,\n",
       "            3.8652e-02,  2.8314e-01,  2.4916e-01, -8.4833e-03,  8.9564e-02,\n",
       "            2.6168e-01, -6.6116e-02,  2.3395e-02,  9.4153e-02, -1.9054e-01,\n",
       "            2.3376e-01,  2.1599e-01, -6.5937e-02, -1.4152e-01,  5.5444e-02,\n",
       "            3.8808e-02, -1.1219e-02, -5.3255e-02, -1.6112e-01, -4.7795e-01,\n",
       "            1.2508e-01, -5.2338e-02,  4.1777e-02,  2.0926e-01,  2.9982e-02,\n",
       "            1.7004e-01,  1.7204e-01, -5.7297e-02,  2.8466e-04,  1.6314e-01,\n",
       "           -5.1908e-02,  7.6928e-02, -1.1935e-01, -6.2036e-03,  3.1347e-02,\n",
       "            1.3693e-01, -1.0162e-01, -1.4422e-01,  1.0109e-03, -2.5197e-04,\n",
       "            2.1691e-02, -1.2884e-01,  1.0547e-01, -9.2394e-02, -6.5803e-02,\n",
       "            3.4240e-02, -1.3812e-01,  3.3172e-02, -3.3335e-01, -2.0084e-01,\n",
       "            1.7392e-01,  4.6246e-02,  2.2051e-02,  9.4377e-02,  2.0062e-01,\n",
       "            4.3850e-02, -7.6612e-02, -6.3365e-02,  1.3656e-01,  1.4408e-01,\n",
       "           -5.1116e-02, -3.3611e-02,  1.0162e-02, -5.0230e-02,  2.5632e-02]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[ 1.3215e-02,  3.0212e-02, -3.0710e-02,  1.7890e-01,  3.6121e-02,\n",
       "           -2.8174e-02,  1.0872e-01, -1.3759e-02, -1.5974e-01,  6.0832e-02,\n",
       "           -1.3585e-01,  3.7831e-01,  7.3944e-02, -2.4111e-01,  5.4381e-02,\n",
       "           -1.4655e-01,  1.6995e-01, -7.7647e-02,  6.6349e-02,  5.8004e-02,\n",
       "            2.4718e-02,  3.9442e-01, -1.9027e-01,  1.0669e-01, -1.8750e-01,\n",
       "            2.8075e-01,  2.3476e-01,  1.8301e-01, -9.3860e-02,  2.4241e-01,\n",
       "            1.9092e-01, -8.1937e-02, -5.2235e-04, -4.2135e-02, -2.4217e-01,\n",
       "            1.4139e-01,  2.5783e-01, -3.2274e-02, -6.5676e-02, -6.9100e-02,\n",
       "           -1.4208e-01, -7.0216e-03,  2.9300e-01, -1.9412e-01, -2.9272e-01,\n",
       "            2.6498e-01,  1.4199e-01,  2.3290e-01,  1.5046e-01,  2.1166e-02,\n",
       "            2.9269e-01, -3.5649e-02,  3.6135e-01, -1.2932e-01,  5.9324e-02,\n",
       "           -1.4415e-02, -1.1051e-01, -3.6016e-02,  1.5944e-01,  2.1245e-01,\n",
       "           -1.2103e-01, -1.1646e-01, -2.2707e-02, -3.3090e-01,  8.6847e-02,\n",
       "           -2.6273e-01, -1.7622e-01, -2.4993e-01, -1.0771e-01, -3.6033e-02,\n",
       "           -1.4121e-01,  1.9582e-01, -2.6022e-01, -1.9941e-02,  2.1816e-01,\n",
       "            5.3948e-02,  9.8683e-02,  4.4742e-02, -1.7305e-01,  2.1960e-01,\n",
       "            4.5063e-01,  2.5700e-01, -1.2626e-01,  1.1513e-01, -1.9291e-01,\n",
       "           -1.8034e-01,  1.1615e-01, -4.1958e-02, -3.4643e-02, -6.1797e-02,\n",
       "           -1.2008e-01, -1.2052e-01, -3.1864e-01, -1.3843e-01,  1.0721e-01,\n",
       "            1.1471e-01, -1.0786e-01, -2.3662e-02,  3.1520e-01, -2.8111e-01,\n",
       "           -7.2884e-02, -2.6587e-01, -3.7838e-01,  1.4581e-01,  1.9589e-01,\n",
       "            2.2909e-02, -7.6993e-02, -1.0789e-01,  1.1059e-01,  2.6694e-01,\n",
       "           -1.5202e-01, -7.6006e-02, -2.4484e-01, -9.2392e-02, -1.7935e-01,\n",
       "           -1.8213e-01, -7.4383e-02, -1.8579e-01,  5.9027e-02,  8.4474e-02,\n",
       "            4.5246e-02, -1.3780e-02,  1.0821e-01,  1.8749e-01,  1.6043e-01,\n",
       "            1.5937e-01, -1.0034e-01, -2.0250e-01, -2.2095e-01,  6.0402e-02,\n",
       "            6.7439e-02,  6.3043e-02,  2.4464e-01, -8.5878e-02, -1.5683e-01,\n",
       "           -2.8975e-01, -7.9612e-02,  3.2556e-01, -1.3328e-02, -1.4028e-01,\n",
       "            1.9724e-01,  1.2632e-01, -3.0653e-01, -2.3824e-01,  5.7867e-02,\n",
       "            1.9741e-01, -1.6169e-01, -1.0004e-01, -7.6077e-03, -1.3522e-01,\n",
       "           -8.0275e-02,  1.8636e-01, -2.6577e-02,  2.2684e-02,  3.2465e-02,\n",
       "           -1.1802e-01, -7.1379e-02,  2.1170e-01,  8.5561e-02,  5.2885e-02,\n",
       "            1.1219e-01,  3.7771e-02, -2.6731e-01, -5.9821e-02, -2.0751e-01,\n",
       "            1.9619e-01, -2.8128e-01, -2.0578e-01,  6.8526e-02,  1.1347e-01,\n",
       "            8.3568e-04, -1.3917e-01, -3.4035e-02, -1.6589e-02, -8.8839e-02,\n",
       "           -2.1097e-01,  5.2465e-01,  4.6858e-02,  1.1552e-01, -5.0072e-02,\n",
       "           -6.1636e-02, -1.4787e-01,  3.2342e-01, -1.1462e-01,  9.1679e-02,\n",
       "           -3.7997e-01,  2.4738e-02,  4.3823e-02,  5.3861e-02, -4.2979e-02,\n",
       "            2.9927e-02, -8.5900e-03,  1.8776e-01,  2.2096e-02, -3.6719e-02,\n",
       "            7.7262e-02,  1.3626e-01,  7.8047e-02,  4.3454e-02,  5.1504e-02,\n",
       "           -2.4337e-02, -3.9114e-01, -1.8369e-01, -6.4402e-02,  2.2775e-01,\n",
       "            1.4492e-01,  4.1881e-01, -6.4089e-02, -1.4536e-01,  5.2569e-02,\n",
       "           -3.2559e-01,  7.1143e-02, -4.1078e-01,  1.4421e-01,  3.4300e-03,\n",
       "           -9.3079e-02,  1.8926e-01, -1.0268e-01,  4.2460e-01,  1.4687e-02,\n",
       "            4.3187e-01,  2.0215e-01,  8.3869e-04,  1.0005e-01,  1.1380e-01,\n",
       "           -6.3010e-02,  3.9214e-02,  1.6026e-01,  7.0844e-02, -3.8441e-02,\n",
       "           -5.2620e-02,  2.1279e-01,  1.8371e-02, -1.5566e-01, -8.3130e-02,\n",
       "           -1.1585e-01,  1.9285e-01,  9.6678e-02,  4.2476e-02,  7.2348e-03,\n",
       "           -4.4091e-02, -2.1313e-01, -1.7566e-01, -2.1572e-01,  8.6001e-02,\n",
       "            1.8727e-01,  5.5065e-02,  2.7563e-01,  1.5423e-01,  4.3772e-01]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[ 4.3228e-02,  7.0980e-02, -2.5736e-01,  4.3738e-01,  5.4604e-02,\n",
       "            1.6077e-02,  5.7946e-02,  7.9215e-02,  9.1533e-02, -6.7587e-02,\n",
       "           -6.4033e-02,  3.2656e-01,  1.1277e-01, -1.2758e-01,  3.2412e-02,\n",
       "            1.7095e-01,  3.9016e-02,  2.6447e-01,  2.1425e-01, -5.1492e-02,\n",
       "            1.1318e-01, -4.2191e-02,  7.2179e-02,  3.7006e-01, -5.7113e-02,\n",
       "           -1.4825e-01,  2.9181e-01,  1.1283e-01, -1.6998e-01,  2.1855e-01,\n",
       "            4.4316e-04,  1.5834e-01,  1.8752e-01, -1.6437e-01, -1.4910e-01,\n",
       "            6.8100e-02,  3.9838e-01,  2.0319e-02, -9.7940e-03,  2.5674e-01,\n",
       "           -1.6985e-01,  1.4500e-01, -8.6197e-03,  5.4102e-03, -1.6867e-01,\n",
       "            3.6639e-01,  1.0277e-01, -8.4786e-02, -5.3926e-02, -4.1237e-02,\n",
       "           -4.9036e-03,  7.1202e-02,  2.9723e-01, -5.2444e-02,  3.6286e-02,\n",
       "           -1.7454e-02, -3.1332e-02, -7.5921e-02,  1.1206e-01,  1.5892e-01,\n",
       "           -2.8532e-02,  1.7946e-01, -7.8067e-02, -9.1458e-02,  1.2213e-01,\n",
       "           -1.0602e-01, -1.1063e-01, -2.3552e-01, -3.5529e-01,  2.0389e-01,\n",
       "            2.2625e-01,  2.5637e-01, -5.9358e-02, -6.1790e-02,  3.2729e-01,\n",
       "            2.4843e-02,  2.2887e-02,  1.1949e-01, -2.1744e-01,  1.6624e-01,\n",
       "            4.3188e-01,  2.8394e-01, -6.4553e-02,  2.4647e-03, -3.2132e-01,\n",
       "           -3.6444e-02,  2.3884e-02, -4.4512e-02,  5.4360e-02,  1.1253e-01,\n",
       "           -6.1725e-02, -1.8065e-01, -6.8636e-02,  1.2913e-02,  1.0513e-01,\n",
       "            1.1103e-01, -2.8567e-01,  4.1211e-02,  3.6301e-02, -3.0289e-01,\n",
       "           -1.2115e-02, -8.6601e-02, -3.8209e-01, -4.0057e-03,  8.7528e-02,\n",
       "           -1.2585e-01, -3.4491e-02, -1.1656e-01, -5.8792e-02,  7.1757e-02,\n",
       "           -2.0589e-01, -1.1957e-01, -3.6888e-02,  3.2825e-02, -3.6641e-03,\n",
       "           -3.1347e-01, -8.9778e-02,  1.8138e-01, -7.7663e-02,  2.9309e-02,\n",
       "            1.7846e-01, -1.0697e-01,  2.1436e-02,  2.0022e-01,  1.9925e-01,\n",
       "           -1.0580e-01, -1.1042e-01, -2.6646e-01, -2.2859e-01, -1.7266e-01,\n",
       "            1.1260e-01,  5.2323e-02,  7.1824e-02, -3.1114e-01, -1.5563e-01,\n",
       "           -2.0575e-01, -8.3857e-02, -1.5209e-01, -1.2917e-01,  2.1603e-02,\n",
       "            4.0604e-02, -2.0186e-01, -3.4973e-02, -1.9547e-01,  7.6912e-02,\n",
       "            2.4166e-02, -9.2053e-02, -9.5726e-02,  4.2474e-02,  2.0494e-02,\n",
       "           -2.6132e-02,  2.1232e-01, -8.3338e-02,  1.1587e-01,  6.0908e-02,\n",
       "           -6.8106e-02, -6.7818e-02,  1.5897e-01, -1.8222e-01,  1.3310e-01,\n",
       "           -5.4455e-02, -1.9169e-01, -2.8164e-01, -8.9937e-02, -1.6923e-01,\n",
       "            9.5779e-02, -1.5709e-01, -1.7954e-01, -3.1695e-02,  7.8690e-02,\n",
       "           -5.0648e-02, -7.6225e-02,  2.0083e-01, -8.6415e-02,  4.3520e-02,\n",
       "           -2.8356e-01, -3.7006e-04, -8.2015e-02,  3.8617e-02, -1.7016e-01,\n",
       "            4.7102e-04, -1.0346e-01,  1.5461e-01, -2.8201e-02,  5.5003e-02,\n",
       "           -5.7640e-02, -2.7280e-01,  5.8703e-02, -2.9771e-01,  1.9342e-01,\n",
       "           -1.8278e-01, -1.5128e-01,  1.1732e-01, -1.4180e-01,  1.1195e-01,\n",
       "            1.0659e-02,  1.0506e-01,  1.4426e-01,  2.3018e-01,  1.2656e-01,\n",
       "            4.6757e-05, -4.0017e-01, -2.4569e-01,  2.1886e-01,  3.5046e-02,\n",
       "           -1.9032e-02,  1.5267e-01, -1.8081e-01, -1.1119e-01,  3.7843e-01,\n",
       "           -2.1339e-01,  8.6890e-02, -2.3081e-02,  1.9089e-01, -8.5501e-02,\n",
       "           -1.4650e-02, -4.7419e-03, -8.2403e-02,  2.1988e-01, -4.5732e-02,\n",
       "            2.8787e-01, -3.3606e-01,  5.5515e-02,  1.9081e-01,  3.0821e-01,\n",
       "            6.4954e-03,  1.1628e-01,  7.1991e-02,  2.8963e-01, -3.7435e-02,\n",
       "           -3.4375e-02, -2.9378e-01,  1.3299e-01,  1.3416e-01, -1.2502e-01,\n",
       "            7.9094e-02,  2.7692e-01,  1.7700e-01, -2.0568e-01, -4.1871e-02,\n",
       "           -1.8332e-02, -1.8749e-01,  3.2077e-02, -1.0143e-01, -1.4736e-02,\n",
       "            2.1953e-01,  2.0332e-01, -9.1303e-02, -4.0274e-02,  3.6928e-01]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[ 0.0382,  0.0443, -0.0840, -0.1335, -0.0781,  0.2271, -0.2701,\n",
       "            0.1656, -0.3046, -0.0272,  0.0542,  0.1268,  0.1283, -0.0700,\n",
       "           -0.0667, -0.0017,  0.3672, -0.1902,  0.0492,  0.1976, -0.1558,\n",
       "            0.1153,  0.1196, -0.3739,  0.0309,  0.3552,  0.1110,  0.0128,\n",
       "           -0.2328,  0.2776,  0.0265, -0.2145, -0.2232, -0.1761,  0.0775,\n",
       "            0.1087,  0.2484, -0.3020, -0.1096, -0.0012,  0.3995, -0.0177,\n",
       "            0.1268,  0.0151,  0.1036, -0.1185, -0.1919,  0.0156,  0.0335,\n",
       "            0.0368,  0.1995,  0.1488,  0.2401, -0.0274, -0.1895, -0.0892,\n",
       "            0.0621,  0.1636,  0.0685,  0.0025,  0.1435,  0.0489, -0.1104,\n",
       "            0.0009, -0.2029, -0.0724, -0.3470,  0.1503,  0.0405,  0.2975,\n",
       "            0.0776,  0.0355,  0.0066, -0.0539, -0.2197, -0.0315, -0.3712,\n",
       "            0.0301,  0.0024,  0.1335, -0.1247,  0.0676,  0.1655, -0.0548,\n",
       "            0.0374,  0.0872,  0.0421,  0.1077,  0.0074, -0.1815, -0.0760,\n",
       "            0.2502,  0.2029,  0.0769,  0.0844, -0.1932,  0.2253, -0.2945,\n",
       "            0.0636,  0.0452,  0.2148, -0.3180, -0.0237,  0.2600, -0.1178,\n",
       "           -0.0669,  0.0959,  0.1157, -0.0332,  0.3827, -0.0354, -0.2919,\n",
       "           -0.1062, -0.1156,  0.4326, -0.0255, -0.3462,  0.0912,  0.0276,\n",
       "            0.2269, -0.3886,  0.0721,  0.1724, -0.0100, -0.1322, -0.1017,\n",
       "           -0.0402,  0.0064, -0.0614,  0.1628, -0.1033,  0.1012, -0.0939,\n",
       "            0.2079, -0.2949, -0.2439, -0.2223, -0.3688,  0.2203, -0.0427,\n",
       "            0.1522, -0.0658,  0.0872,  0.0425, -0.0464,  0.4270,  0.2854,\n",
       "           -0.0090, -0.2324,  0.2716, -0.1713,  0.1995,  0.2103, -0.1695,\n",
       "           -0.1486,  0.0718,  0.0011, -0.1420, -0.1383,  0.1061, -0.1210,\n",
       "           -0.0357, -0.0672, -0.0855,  0.0955,  0.0716,  0.2472,  0.0885,\n",
       "           -0.0254, -0.2593, -0.3771,  0.0403,  0.0582, -0.2657,  0.0298,\n",
       "            0.1224,  0.4331,  0.1264,  0.0793, -0.2075,  0.3133,  0.0033,\n",
       "            0.0499,  0.0614, -0.3114,  0.0237,  0.2008,  0.0031,  0.0321,\n",
       "            0.3099,  0.2835,  0.0861,  0.0457,  0.0484,  0.1098,  0.1676,\n",
       "            0.0421,  0.0820, -0.0919, -0.3489,  0.0664, -0.0512, -0.2653,\n",
       "           -0.0784, -0.1128, -0.0481,  0.0655, -0.0319,  0.0554,  0.0779,\n",
       "            0.3419, -0.2864,  0.2706,  0.0538,  0.1545, -0.2128,  0.0883,\n",
       "            0.0309,  0.0569,  0.0110, -0.0134, -0.0664,  0.1986, -0.2012,\n",
       "            0.0315, -0.2107,  0.0623,  0.1926, -0.3153,  0.1898, -0.2478,\n",
       "            0.1249,  0.0722, -0.1984,  0.2333,  0.3158,  0.1193, -0.0053,\n",
       "            0.3348,  0.1282, -0.0522, -0.0206,  0.1141, -0.0812,  0.3318,\n",
       "           -0.0365,  0.1432,  0.1423,  0.0461,  0.0223]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[ 3.4325e-02,  1.1510e-01, -5.6928e-02, -1.1964e-01, -1.0432e-01,\n",
       "            1.3610e-01, -1.4670e-01,  1.0164e-01, -1.6065e-01, -4.2137e-03,\n",
       "            4.7350e-02,  7.8816e-02,  1.5088e-01, -4.9395e-02, -7.1945e-02,\n",
       "            7.7223e-03,  1.7018e-01, -9.7648e-02,  3.2421e-02,  9.0055e-02,\n",
       "           -9.9957e-02,  8.2182e-03,  5.9734e-02, -1.0652e-01,  6.9978e-02,\n",
       "            1.7160e-01,  1.4911e-01, -1.8478e-02, -1.1198e-01,  1.5501e-01,\n",
       "           -4.8325e-03, -9.6824e-02, -8.5876e-02, -5.7162e-02,  7.0349e-02,\n",
       "            1.6311e-01,  1.1270e-01, -1.1575e-01, -3.0660e-02,  2.5903e-02,\n",
       "            1.8497e-01,  7.2378e-03,  1.4628e-01, -3.0614e-02,  7.8557e-02,\n",
       "           -5.6300e-02, -5.2229e-02,  1.3693e-02,  3.0271e-02, -8.4749e-03,\n",
       "            1.2949e-01,  1.1434e-01,  1.1326e-01,  7.9956e-03, -1.1576e-01,\n",
       "           -4.2039e-02,  6.4813e-02,  5.4011e-02,  2.7069e-02,  3.9567e-02,\n",
       "            5.8058e-02,  4.9071e-02, -8.1426e-02, -2.8053e-03, -1.0547e-01,\n",
       "           -4.4271e-02, -1.4700e-01,  2.2549e-02,  1.2378e-02,  1.5386e-01,\n",
       "            1.2447e-02,  5.1774e-02, -5.1161e-03, -1.1458e-02, -1.7915e-02,\n",
       "           -2.8553e-02, -1.8303e-01, -2.0958e-02,  3.8464e-03,  1.0594e-01,\n",
       "           -3.0808e-02,  6.3208e-02,  8.3921e-02,  4.2268e-03,  3.6123e-03,\n",
       "            3.6766e-02,  4.4741e-02, -7.9712e-03, -6.8395e-03, -1.3939e-01,\n",
       "           -4.1427e-02,  9.1552e-02,  1.0863e-01,  6.9435e-02,  6.8435e-02,\n",
       "           -1.2590e-01,  1.0171e-01, -1.1324e-01,  6.7117e-02,  1.3427e-02,\n",
       "            1.2968e-01, -1.7674e-01, -1.9183e-02,  2.0032e-01, -4.6818e-02,\n",
       "           -7.6731e-02,  7.0708e-02,  5.9877e-02, -3.3924e-02,  1.9186e-01,\n",
       "            4.6069e-03, -2.4972e-01, -6.8564e-02, -2.0207e-02,  1.8732e-01,\n",
       "           -2.9399e-02, -1.3450e-01,  7.6449e-02,  1.3701e-02,  1.0963e-01,\n",
       "           -1.1082e-01,  2.7495e-02,  1.1901e-01,  2.6400e-02, -1.0541e-01,\n",
       "           -6.3831e-02, -3.1581e-02,  3.5410e-02,  2.3702e-02,  9.8382e-02,\n",
       "           -1.1308e-01,  8.3240e-02, -5.6398e-02,  1.1676e-01, -1.2044e-01,\n",
       "           -1.1557e-01, -9.2699e-02, -2.0247e-01,  9.6640e-02, -5.7855e-02,\n",
       "            1.2130e-01, -7.6535e-02,  2.7255e-02,  1.1167e-01,  3.4264e-03,\n",
       "            1.6033e-01,  1.1107e-01, -1.9780e-02, -8.7175e-02,  1.2653e-01,\n",
       "           -1.4573e-01,  1.4585e-01,  6.9500e-02, -1.1280e-01, -1.2561e-01,\n",
       "            9.2039e-03, -6.8621e-02, -7.4579e-02, -7.7015e-02,  8.7906e-02,\n",
       "           -7.6646e-02, -1.8720e-02, -7.3945e-02, -6.9840e-02,  4.8775e-02,\n",
       "            3.0182e-05,  1.2198e-01,  1.6013e-01,  1.0628e-02, -9.7645e-02,\n",
       "           -1.7919e-01,  8.5290e-02,  4.2666e-02, -1.1355e-01,  6.0749e-02,\n",
       "            4.6845e-02,  1.5901e-01,  6.3961e-02,  1.6398e-01, -2.0890e-01,\n",
       "            9.2011e-02, -2.8583e-02,  7.7990e-03,  5.4758e-02, -1.2797e-01,\n",
       "            4.2074e-02,  5.1194e-02, -9.4177e-03,  1.1948e-02,  8.9945e-02,\n",
       "            1.4351e-01,  7.2626e-02,  4.7601e-02, -1.1933e-02,  2.2645e-02,\n",
       "            9.7581e-02,  1.1274e-02,  5.1728e-02, -1.4617e-01, -1.3976e-01,\n",
       "            8.7853e-02, -9.4630e-03, -1.4345e-01, -4.7167e-02, -7.9685e-02,\n",
       "           -6.8155e-02,  8.0535e-02, -4.8593e-02,  2.6080e-02,  2.8674e-03,\n",
       "            1.5790e-01, -1.1769e-01,  1.3814e-01,  3.7680e-02,  5.2144e-02,\n",
       "           -1.0217e-01,  1.5964e-01, -7.4991e-03,  3.5805e-03,  1.8392e-02,\n",
       "            1.1343e-02, -9.7163e-02,  8.1110e-02, -6.8270e-02,  5.6752e-02,\n",
       "           -1.8660e-01,  5.9590e-02,  1.4349e-01, -1.0407e-01,  7.6256e-02,\n",
       "           -1.7024e-01,  9.6261e-02,  3.5899e-02, -1.2444e-01,  1.2635e-01,\n",
       "            1.5362e-01,  9.6962e-02, -1.1999e-02,  1.6686e-01,  1.0464e-01,\n",
       "           -1.8250e-02, -2.0293e-02,  7.4344e-02, -2.6627e-02,  1.7329e-01,\n",
       "           -3.2520e-02,  1.2367e-01,  1.0525e-01, -1.5616e-03,  5.3942e-03]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[ 0.0226,  0.0786, -0.0455, -0.0867, -0.0842,  0.0356, -0.0964,\n",
       "            0.0594, -0.0577, -0.0115,  0.0423,  0.0593,  0.0800, -0.0251,\n",
       "           -0.0322,  0.0165,  0.1302, -0.0361,  0.0283,  0.0748, -0.0561,\n",
       "           -0.0140,  0.0240, -0.0368,  0.0578,  0.1142,  0.1180, -0.0168,\n",
       "           -0.0576,  0.0867, -0.0166, -0.0470, -0.0498, -0.0210,  0.0300,\n",
       "            0.1148,  0.0725, -0.0750, -0.0040,  0.0104,  0.0966,  0.0106,\n",
       "            0.1038, -0.0256,  0.0363, -0.0310, -0.0155, -0.0093,  0.0103,\n",
       "           -0.0206,  0.0875,  0.0806,  0.0651,  0.0299, -0.0609, -0.0201,\n",
       "            0.0553,  0.0287,  0.0204,  0.0359,  0.0107,  0.0324, -0.0623,\n",
       "           -0.0005, -0.0612, -0.0251, -0.0778, -0.0021, -0.0067,  0.1102,\n",
       "           -0.0036,  0.0328,  0.0024, -0.0030,  0.0120, -0.0183, -0.1193,\n",
       "           -0.0391, -0.0092,  0.0712,  0.0063,  0.0277,  0.0367,  0.0114,\n",
       "           -0.0060, -0.0040,  0.0094, -0.0353, -0.0142, -0.0874, -0.0259,\n",
       "            0.0275,  0.0710,  0.0510,  0.0572, -0.0691,  0.0429, -0.0740,\n",
       "            0.0482, -0.0027,  0.0621, -0.0910, -0.0179,  0.1404, -0.0242,\n",
       "           -0.0366,  0.0379,  0.0421, -0.0343,  0.1132,  0.0169, -0.1461,\n",
       "           -0.0316,  0.0070,  0.1069, -0.0249, -0.0502,  0.0620, -0.0016,\n",
       "            0.0632, -0.0520, -0.0041,  0.0720,  0.0342, -0.0617, -0.0456,\n",
       "           -0.0251,  0.0382,  0.0380,  0.0379, -0.0883,  0.0541, -0.0241,\n",
       "            0.0945, -0.0718, -0.0802, -0.0573, -0.1247,  0.0526, -0.0403,\n",
       "            0.0565, -0.0562,  0.0028,  0.0693,  0.0233,  0.0689,  0.0643,\n",
       "           -0.0238, -0.0504,  0.0667, -0.0821,  0.0819,  0.0293, -0.0725,\n",
       "           -0.0633, -0.0236, -0.0737, -0.0342, -0.0433,  0.0535, -0.0660,\n",
       "           -0.0036, -0.0335, -0.0512,  0.0081, -0.0277,  0.0534,  0.1019,\n",
       "            0.0207, -0.0515, -0.1132,  0.0787,  0.0123, -0.0839,  0.0320,\n",
       "            0.0107,  0.0680,  0.0454,  0.1397, -0.1129,  0.0311, -0.0347,\n",
       "            0.0078,  0.0132, -0.0535,  0.0317,  0.0060, -0.0131, -0.0375,\n",
       "            0.0207,  0.1076,  0.0583,  0.0337, -0.0210,  0.0019,  0.0602,\n",
       "            0.0128,  0.0326, -0.0574, -0.0781,  0.0567,  0.0172, -0.0784,\n",
       "            0.0043, -0.0604, -0.0407,  0.0638, -0.0411, -0.0021, -0.0168,\n",
       "            0.0870, -0.0574,  0.0732,  0.0225,  0.0054, -0.0588,  0.1243,\n",
       "           -0.0160,  0.0019,  0.0235,  0.0299, -0.0737,  0.0337, -0.0507,\n",
       "            0.0468, -0.1436,  0.0463,  0.0901, -0.0429,  0.0241, -0.0890,\n",
       "            0.0373,  0.0231, -0.0727,  0.0490,  0.0856,  0.0411, -0.0147,\n",
       "            0.0892,  0.0518, -0.0103, -0.0111,  0.0557, -0.0206,  0.1164,\n",
       "           -0.0266,  0.0812,  0.0854, -0.0199,  0.0045]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[ 0.0084,  0.0609, -0.0384, -0.0666, -0.0590, -0.0135, -0.0685,\n",
       "            0.0341, -0.0125, -0.0170,  0.0389,  0.0497,  0.0479, -0.0037,\n",
       "           -0.0127,  0.0245,  0.0983,  0.0009,  0.0199,  0.0612, -0.0276,\n",
       "           -0.0166,  0.0045, -0.0053,  0.0459,  0.0741,  0.0918, -0.0079,\n",
       "           -0.0289,  0.0469, -0.0256, -0.0229, -0.0362, -0.0052,  0.0171,\n",
       "            0.0846,  0.0469, -0.0516,  0.0107, -0.0045,  0.0440,  0.0090,\n",
       "            0.0763, -0.0144,  0.0115, -0.0188,  0.0026, -0.0257, -0.0088,\n",
       "           -0.0167,  0.0654,  0.0650,  0.0387,  0.0387, -0.0347, -0.0099,\n",
       "            0.0416,  0.0111,  0.0174,  0.0251, -0.0077,  0.0211, -0.0452,\n",
       "            0.0031, -0.0364, -0.0134, -0.0416, -0.0061, -0.0135,  0.0757,\n",
       "           -0.0102,  0.0171,  0.0067, -0.0072,  0.0181, -0.0137, -0.0855,\n",
       "           -0.0366, -0.0172,  0.0517,  0.0191,  0.0049,  0.0132,  0.0073,\n",
       "           -0.0082, -0.0265, -0.0040, -0.0388, -0.0183, -0.0532, -0.0177,\n",
       "            0.0028,  0.0465,  0.0367,  0.0443, -0.0355,  0.0176, -0.0547,\n",
       "            0.0408, -0.0111,  0.0335, -0.0413, -0.0221,  0.1008, -0.0128,\n",
       "           -0.0154,  0.0162,  0.0320, -0.0356,  0.0658,  0.0107, -0.0846,\n",
       "           -0.0149,  0.0221,  0.0571, -0.0247, -0.0176,  0.0446, -0.0073,\n",
       "            0.0468, -0.0185, -0.0213,  0.0489,  0.0392, -0.0292, -0.0236,\n",
       "           -0.0156,  0.0321,  0.0396,  0.0047, -0.0726,  0.0309, -0.0050,\n",
       "            0.0774, -0.0451, -0.0538, -0.0368, -0.0773,  0.0258, -0.0300,\n",
       "            0.0201, -0.0447, -0.0080,  0.0495,  0.0229,  0.0282,  0.0344,\n",
       "           -0.0229, -0.0314,  0.0280, -0.0497,  0.0387,  0.0168, -0.0464,\n",
       "           -0.0190, -0.0237, -0.0673, -0.0119, -0.0329,  0.0382, -0.0580,\n",
       "            0.0046, -0.0061, -0.0336, -0.0108, -0.0344,  0.0140,  0.0711,\n",
       "            0.0260, -0.0279, -0.0697,  0.0684,  0.0029, -0.0700,  0.0158,\n",
       "           -0.0098,  0.0208,  0.0257,  0.1139, -0.0672, -0.0029, -0.0347,\n",
       "            0.0135, -0.0096, -0.0196,  0.0177, -0.0138, -0.0152, -0.0568,\n",
       "           -0.0080,  0.0870,  0.0418,  0.0228, -0.0161, -0.0076,  0.0318,\n",
       "            0.0198,  0.0210, -0.0144, -0.0353,  0.0382,  0.0294, -0.0477,\n",
       "            0.0124, -0.0371, -0.0214,  0.0503, -0.0353, -0.0161, -0.0195,\n",
       "            0.0576, -0.0250,  0.0323,  0.0180, -0.0099, -0.0344,  0.0935,\n",
       "           -0.0261,  0.0106,  0.0231,  0.0366, -0.0570,  0.0118, -0.0440,\n",
       "            0.0406, -0.1131,  0.0345,  0.0509, -0.0121, -0.0018, -0.0402,\n",
       "            0.0175,  0.0220, -0.0433,  0.0159,  0.0496,  0.0168, -0.0140,\n",
       "            0.0379,  0.0162, -0.0042, -0.0037,  0.0455, -0.0179,  0.0775,\n",
       "           -0.0198,  0.0544,  0.0727, -0.0276,  0.0093]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[-2.1161e-03,  4.9760e-02, -3.5893e-02, -5.4989e-02, -3.6896e-02,\n",
       "           -3.7095e-02, -5.3320e-02,  1.9149e-02,  6.3621e-03, -2.0576e-02,\n",
       "            3.5867e-02,  4.6069e-02,  3.2769e-02,  1.1272e-02, -1.9456e-03,\n",
       "            2.9055e-02,  7.5978e-02,  2.2489e-02,  1.1552e-02,  5.0937e-02,\n",
       "           -1.0835e-02, -1.3046e-02, -6.6718e-03,  8.4122e-03,  3.5006e-02,\n",
       "            4.8646e-02,  7.3149e-02,  2.2024e-03, -1.5913e-02,  2.3369e-02,\n",
       "           -3.1619e-02, -1.2841e-02, -3.0781e-02,  1.6673e-03,  1.5312e-02,\n",
       "            6.5941e-02,  3.1935e-02, -3.7914e-02,  1.9321e-02, -1.4893e-02,\n",
       "            1.4952e-02,  5.7375e-03,  6.0648e-02, -3.7852e-03, -1.7315e-03,\n",
       "           -1.2962e-02,  1.2114e-02, -3.6458e-02, -2.2622e-02, -9.2938e-03,\n",
       "            5.3271e-02,  5.7238e-02,  2.6276e-02,  4.0487e-02, -2.4380e-02,\n",
       "           -3.9315e-03,  2.8778e-02,  9.0743e-04,  1.4768e-02,  1.5109e-02,\n",
       "           -1.4591e-02,  1.3991e-02, -3.1957e-02,  6.3408e-03, -2.4562e-02,\n",
       "           -4.9635e-03, -2.3246e-02, -3.9950e-03, -1.4163e-02,  5.2051e-02,\n",
       "           -1.2330e-02,  4.9976e-03,  9.0517e-03, -1.4258e-02,  1.6360e-02,\n",
       "           -1.2553e-02, -6.6612e-02, -2.7581e-02, -1.9899e-02,  4.0467e-02,\n",
       "            2.3747e-02, -8.2479e-03,  2.7301e-03,  5.6087e-04, -8.1753e-03,\n",
       "           -3.8227e-02, -7.6993e-03, -3.4680e-02, -2.0596e-02, -3.2819e-02,\n",
       "           -1.3333e-02, -6.6193e-03,  3.1120e-02,  2.6939e-02,  3.4561e-02,\n",
       "           -1.7002e-02,  6.8738e-03, -4.5192e-02,  3.8491e-02, -1.4867e-02,\n",
       "            2.3601e-02, -1.7494e-02, -2.6861e-02,  7.7459e-02, -7.3716e-03,\n",
       "           -4.0630e-03,  2.3505e-03,  2.7122e-02, -3.6559e-02,  3.6966e-02,\n",
       "            1.6332e-03, -5.1019e-02, -5.8533e-03,  2.9003e-02,  3.0040e-02,\n",
       "           -2.5234e-02, -3.8815e-03,  3.0362e-02, -9.4585e-03,  4.3202e-02,\n",
       "           -3.5409e-03, -3.0378e-02,  3.7300e-02,  4.0275e-02, -6.8199e-03,\n",
       "           -4.8868e-03, -6.9341e-03,  2.4403e-02,  3.7402e-02, -1.3165e-02,\n",
       "           -6.3094e-02,  1.4031e-02,  4.6520e-03,  6.5637e-02, -2.8593e-02,\n",
       "           -3.5373e-02, -2.6649e-02, -5.1924e-02,  9.5015e-03, -2.4779e-02,\n",
       "           -8.6836e-04, -3.9406e-02, -1.1627e-02,  3.9191e-02,  1.6148e-02,\n",
       "            1.1602e-02,  1.8790e-02, -2.0701e-02, -2.2446e-02,  5.3173e-03,\n",
       "           -3.2811e-02,  1.2493e-02,  1.4317e-02, -3.1199e-02,  7.3835e-03,\n",
       "           -1.5801e-02, -5.8632e-02,  1.6556e-04, -3.0626e-02,  3.1713e-02,\n",
       "           -5.3641e-02,  8.4447e-03,  1.2167e-02, -2.1643e-02, -2.0135e-02,\n",
       "           -3.3866e-02, -7.1572e-03,  5.4796e-02,  2.9959e-02, -1.7851e-02,\n",
       "           -4.2526e-02,  5.8977e-02,  8.8584e-06, -6.3475e-02,  6.2030e-03,\n",
       "           -2.0303e-02, -2.6382e-03,  1.0647e-02,  9.4064e-02, -4.4957e-02,\n",
       "           -1.9891e-02, -3.2701e-02,  1.9325e-02, -2.2180e-02, -2.8637e-03,\n",
       "            7.2048e-03, -2.1994e-02, -1.6170e-02, -6.3662e-02, -1.9998e-02,\n",
       "            7.4229e-02,  2.6288e-02,  1.5670e-02, -8.8125e-03, -1.1647e-02,\n",
       "            1.3556e-02,  2.5518e-02,  1.3710e-02,  4.9990e-03, -8.1104e-03,\n",
       "            2.5730e-02,  3.6550e-02, -3.1962e-02,  7.1082e-03, -1.9325e-02,\n",
       "           -9.4543e-03,  3.9838e-02, -3.2117e-02, -2.3108e-02, -1.5867e-02,\n",
       "            4.4311e-02, -8.5914e-03,  7.3349e-03,  1.7098e-02, -1.3575e-02,\n",
       "           -1.9567e-02,  6.9377e-02, -3.3673e-02,  2.0260e-02,  2.0755e-02,\n",
       "            3.7382e-02, -4.6068e-02,  2.5203e-03, -4.1312e-02,  3.5838e-02,\n",
       "           -9.1832e-02,  2.7142e-02,  2.5545e-02,  2.5674e-03, -1.5326e-02,\n",
       "           -1.1960e-02,  1.3483e-02,  2.3970e-02, -2.9087e-02,  3.9005e-03,\n",
       "            2.9306e-02,  5.9237e-03, -1.2270e-02,  4.9616e-03, -5.3284e-03,\n",
       "           -3.5279e-04,  3.0151e-03,  3.9939e-02, -1.5887e-02,  5.3759e-02,\n",
       "           -1.4158e-02,  3.6821e-02,  6.4408e-02, -3.0365e-02,  1.3989e-02]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[-0.0086,  0.0422, -0.0359, -0.0482, -0.0199, -0.0485, -0.0451,\n",
       "            0.0102,  0.0142, -0.0229,  0.0332,  0.0454,  0.0255,  0.0206,\n",
       "            0.0040,  0.0307,  0.0611,  0.0350,  0.0049,  0.0439, -0.0015,\n",
       "           -0.0088, -0.0133,  0.0144,  0.0261,  0.0333,  0.0612,  0.0106,\n",
       "           -0.0107,  0.0098, -0.0356, -0.0092, -0.0285,  0.0049,  0.0171,\n",
       "            0.0542,  0.0237, -0.0296,  0.0246, -0.0212, -0.0008,  0.0027,\n",
       "            0.0523,  0.0044, -0.0083, -0.0101,  0.0175, -0.0433, -0.0313,\n",
       "           -0.0029,  0.0461,  0.0527,  0.0209,  0.0389, -0.0215,  0.0002,\n",
       "            0.0186, -0.0047,  0.0122,  0.0076, -0.0167,  0.0098, -0.0228,\n",
       "            0.0086, -0.0198,  0.0013, -0.0145, -0.0010, -0.0125,  0.0372,\n",
       "           -0.0126, -0.0039,  0.0102, -0.0207,  0.0134, -0.0130, -0.0558,\n",
       "           -0.0184, -0.0193,  0.0341,  0.0257, -0.0159, -0.0013, -0.0056,\n",
       "           -0.0079, -0.0439, -0.0075, -0.0294, -0.0219, -0.0216, -0.0108,\n",
       "           -0.0103,  0.0218,  0.0203,  0.0283, -0.0069,  0.0019, -0.0402,\n",
       "            0.0384, -0.0165,  0.0215, -0.0078, -0.0307,  0.0641, -0.0048,\n",
       "            0.0024, -0.0066,  0.0252, -0.0374,  0.0198, -0.0056, -0.0337,\n",
       "           -0.0006,  0.0313,  0.0165, -0.0260,  0.0029,  0.0203, -0.0100,\n",
       "            0.0442,  0.0015, -0.0347,  0.0316,  0.0392,  0.0079,  0.0089,\n",
       "           -0.0002,  0.0178,  0.0348, -0.0223, -0.0577,  0.0030,  0.0090,\n",
       "            0.0586, -0.0184, -0.0226, -0.0221, -0.0388, -0.0005, -0.0226,\n",
       "           -0.0127, -0.0376, -0.0119,  0.0330,  0.0088,  0.0052,  0.0117,\n",
       "           -0.0186, -0.0183, -0.0079, -0.0243, -0.0023,  0.0147, -0.0228,\n",
       "            0.0214, -0.0082, -0.0509,  0.0069, -0.0303,  0.0291, -0.0515,\n",
       "            0.0100,  0.0240, -0.0147, -0.0251, -0.0319, -0.0185,  0.0457,\n",
       "            0.0331, -0.0147, -0.0261,  0.0515, -0.0013, -0.0603,  0.0002,\n",
       "           -0.0252, -0.0143,  0.0003,  0.0804, -0.0344, -0.0275, -0.0307,\n",
       "            0.0238, -0.0288,  0.0062,  0.0008, -0.0250, -0.0162, -0.0658,\n",
       "           -0.0249,  0.0661,  0.0136,  0.0117, -0.0028, -0.0133,  0.0025,\n",
       "            0.0293,  0.0090,  0.0136,  0.0082,  0.0173,  0.0415, -0.0237,\n",
       "           -0.0002, -0.0080, -0.0021,  0.0322, -0.0309, -0.0266, -0.0109,\n",
       "            0.0380, -0.0008, -0.0073,  0.0171, -0.0133, -0.0109,  0.0522,\n",
       "           -0.0386,  0.0280,  0.0183,  0.0359, -0.0394, -0.0014, -0.0398,\n",
       "            0.0323, -0.0778,  0.0234,  0.0094,  0.0095, -0.0226,  0.0040,\n",
       "            0.0148,  0.0259, -0.0238,  0.0013,  0.0178,  0.0009, -0.0105,\n",
       "           -0.0162, -0.0178,  0.0021,  0.0089,  0.0367, -0.0137,  0.0393,\n",
       "           -0.0100,  0.0259,  0.0594, -0.0315,  0.0175]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[-1.2100e-02,  3.6923e-02, -3.7038e-02, -4.3963e-02, -7.7740e-03,\n",
       "           -5.3942e-02, -4.0688e-02,  4.8353e-03,  1.7337e-02, -2.4580e-02,\n",
       "            3.1040e-02,  4.5809e-02,  2.1877e-02,  2.6007e-02,  7.0077e-03,\n",
       "            3.0536e-02,  5.1434e-02,  4.2268e-02,  2.3603e-05,  3.9414e-02,\n",
       "            3.5508e-03, -5.4884e-03, -1.7147e-02,  1.6830e-02,  1.9411e-02,\n",
       "            2.4308e-02,  5.4017e-02,  1.6551e-02, -8.9418e-03,  2.2963e-03,\n",
       "           -3.8137e-02, -8.1461e-03, -2.7603e-02,  6.5467e-03,  1.9410e-02,\n",
       "            4.6762e-02,  1.9622e-02, -2.4383e-02,  2.8035e-02, -2.4933e-02,\n",
       "           -9.1756e-03,  4.4542e-04,  4.8087e-02,  1.0105e-02, -1.1299e-02,\n",
       "           -8.6533e-03,  2.0727e-02, -4.7459e-02, -3.6375e-02,  1.6319e-03,\n",
       "            4.1573e-02,  4.9640e-02,  1.8878e-02,  3.6187e-02, -2.1762e-02,\n",
       "            3.4168e-03,  1.1070e-02, -7.5261e-03,  1.0034e-02,  2.4232e-03,\n",
       "           -1.6774e-02,  7.4259e-03, -1.6987e-02,  9.9870e-03, -1.8425e-02,\n",
       "            5.7841e-03, -1.0596e-02,  1.2477e-03, -1.0531e-02,  2.8427e-02,\n",
       "           -1.2291e-02, -1.0140e-02,  1.0803e-02, -2.5490e-02,  1.1168e-02,\n",
       "           -1.3940e-02, -4.9527e-02, -1.1186e-02, -1.7251e-02,  3.0560e-02,\n",
       "            2.6750e-02, -2.0368e-02, -2.5142e-03, -1.0392e-02, -7.7786e-03,\n",
       "           -4.6413e-02, -6.1516e-03, -2.4973e-02, -2.2658e-02, -1.5880e-02,\n",
       "           -9.2615e-03, -1.1966e-02,  1.6104e-02,  1.5856e-02,  2.4621e-02,\n",
       "           -1.4146e-03, -5.9109e-04, -3.7602e-02,  3.8952e-02, -1.7313e-02,\n",
       "            2.2283e-02, -4.8539e-03, -3.3425e-02,  5.6580e-02, -3.6562e-03,\n",
       "            6.3464e-03, -1.2564e-02,  2.4867e-02, -3.8175e-02,  9.7031e-03,\n",
       "           -1.0314e-02, -2.5020e-02,  2.3120e-03,  3.1353e-02,  1.0011e-02,\n",
       "           -2.6764e-02,  6.8914e-03,  1.3910e-02, -9.8581e-03,  4.6331e-02,\n",
       "            2.1117e-03, -3.6268e-02,  2.8926e-02,  3.7326e-02,  1.7368e-02,\n",
       "            1.8153e-02,  4.5961e-03,  1.2738e-02,  3.2733e-02, -2.6804e-02,\n",
       "           -5.4758e-02, -3.7572e-03,  1.0822e-02,  5.4715e-02, -1.2190e-02,\n",
       "           -1.4126e-02, -2.0391e-02, -3.2252e-02, -6.6188e-03, -2.1882e-02,\n",
       "           -1.9347e-02, -3.7251e-02, -1.0917e-02,  2.8828e-02,  2.8222e-03,\n",
       "            2.7409e-03,  9.1666e-03, -1.7044e-02, -1.6407e-02, -1.5620e-02,\n",
       "           -2.0199e-02, -1.0399e-02,  1.5512e-02, -1.8441e-02,  2.8368e-02,\n",
       "           -2.7333e-03, -4.5140e-02,  1.0733e-02, -3.0247e-02,  2.7987e-02,\n",
       "           -5.0570e-02,  1.0417e-02,  3.1473e-02, -1.0934e-02, -2.7943e-02,\n",
       "           -3.0287e-02, -2.4552e-02,  4.0333e-02,  3.5591e-02, -1.4515e-02,\n",
       "           -1.6356e-02,  4.6080e-02, -2.2269e-03, -5.8725e-02, -3.5806e-03,\n",
       "           -2.7354e-02, -2.0311e-02, -6.4713e-03,  7.1531e-02, -2.9671e-02,\n",
       "           -3.0485e-02, -2.9318e-02,  2.6826e-02, -3.2277e-02,  1.1561e-02,\n",
       "           -2.5046e-03, -2.5890e-02, -1.5922e-02, -6.6443e-02, -2.6823e-02,\n",
       "            6.0736e-02,  4.3326e-03,  9.8380e-03,  1.3454e-03, -1.3955e-02,\n",
       "           -4.0876e-03,  3.1621e-02,  5.9902e-03,  1.7504e-02,  1.7521e-02,\n",
       "            1.1440e-02,  4.5173e-02, -1.9437e-02, -6.1933e-03, -1.4188e-03,\n",
       "            2.3438e-03,  2.6937e-02, -3.0918e-02, -2.8307e-02, -6.6343e-03,\n",
       "            3.4726e-02,  2.5872e-03, -1.5682e-02,  1.7124e-02, -1.1911e-02,\n",
       "           -6.0100e-03,  4.0520e-02, -4.1663e-02,  3.3640e-02,  1.6305e-02,\n",
       "            3.3819e-02, -3.5612e-02, -3.1134e-03, -3.8828e-02,  2.9809e-02,\n",
       "           -6.9006e-02,  2.1943e-02, -6.6137e-04,  1.2943e-02, -2.6742e-02,\n",
       "            1.2785e-02,  1.7231e-02,  2.7170e-02, -2.2918e-02,  2.1840e-03,\n",
       "            1.1268e-02, -1.4760e-03, -8.9792e-03, -2.9336e-02, -2.4739e-02,\n",
       "            3.8426e-03,  1.3674e-02,  3.4908e-02, -1.1573e-02,  3.0474e-02,\n",
       "           -7.1039e-03,  1.9347e-02,  5.6653e-02, -3.2140e-02,  1.9806e-02]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[-0.0138,  0.0333, -0.0384, -0.0413,  0.0006, -0.0566, -0.0384,\n",
       "            0.0016,  0.0187, -0.0258,  0.0294,  0.0465,  0.0201,  0.0289,\n",
       "            0.0084,  0.0296,  0.0452,  0.0463, -0.0033,  0.0368,  0.0061,\n",
       "           -0.0033, -0.0194,  0.0177,  0.0147,  0.0192,  0.0499,  0.0204,\n",
       "           -0.0086, -0.0017, -0.0398, -0.0080, -0.0273,  0.0075,  0.0213,\n",
       "            0.0421,  0.0178, -0.0211,  0.0303, -0.0270, -0.0137, -0.0010,\n",
       "            0.0461,  0.0140, -0.0126, -0.0079,  0.0228, -0.0499, -0.0392,\n",
       "            0.0045,  0.0386,  0.0475,  0.0184,  0.0334, -0.0229,  0.0060,\n",
       "            0.0058, -0.0089,  0.0083, -0.0009, -0.0161,  0.0061, -0.0135,\n",
       "            0.0107, -0.0184,  0.0090, -0.0091,  0.0027, -0.0089,  0.0234,\n",
       "           -0.0119, -0.0143,  0.0112, -0.0288,  0.0100, -0.0149, -0.0459,\n",
       "           -0.0060, -0.0149,  0.0286,  0.0275, -0.0230, -0.0026, -0.0137,\n",
       "           -0.0079, -0.0474, -0.0048, -0.0219, -0.0230, -0.0131, -0.0082,\n",
       "           -0.0130,  0.0127,  0.0128,  0.0226,  0.0015, -0.0021, -0.0362,\n",
       "            0.0396, -0.0178,  0.0237, -0.0048, -0.0352,  0.0524, -0.0032,\n",
       "            0.0087, -0.0165,  0.0252, -0.0390,  0.0039, -0.0130, -0.0208,\n",
       "            0.0039,  0.0307,  0.0071, -0.0274,  0.0095,  0.0100, -0.0094,\n",
       "            0.0485,  0.0011, -0.0365,  0.0277,  0.0355,  0.0233,  0.0240,\n",
       "            0.0079,  0.0091,  0.0314, -0.0289, -0.0531, -0.0077,  0.0115,\n",
       "            0.0526, -0.0086, -0.0087, -0.0199, -0.0291, -0.0103, -0.0219,\n",
       "           -0.0230, -0.0375, -0.0095,  0.0259, -0.0015,  0.0018,  0.0086,\n",
       "           -0.0160, -0.0156, -0.0202, -0.0184, -0.0148,  0.0161, -0.0163,\n",
       "            0.0316,  0.0006, -0.0412,  0.0129, -0.0300,  0.0275, -0.0501,\n",
       "            0.0104,  0.0360, -0.0089, -0.0297, -0.0294, -0.0277,  0.0370,\n",
       "            0.0374, -0.0154, -0.0105,  0.0423, -0.0031, -0.0579, -0.0060,\n",
       "           -0.0281, -0.0236, -0.0107,  0.0659, -0.0277, -0.0313, -0.0285,\n",
       "            0.0288, -0.0340,  0.0148, -0.0039, -0.0260, -0.0155, -0.0666,\n",
       "           -0.0275,  0.0572, -0.0021,  0.0092,  0.0039, -0.0142, -0.0079,\n",
       "            0.0331,  0.0041,  0.0193,  0.0227,  0.0074,  0.0477, -0.0173,\n",
       "           -0.0104,  0.0021,  0.0051,  0.0234, -0.0314, -0.0291, -0.0035,\n",
       "            0.0330,  0.0038, -0.0204,  0.0170, -0.0105, -0.0035,  0.0329,\n",
       "           -0.0435,  0.0374,  0.0149,  0.0319, -0.0336, -0.0038, -0.0382,\n",
       "            0.0282, -0.0636,  0.0215, -0.0068,  0.0147, -0.0291,  0.0174,\n",
       "            0.0194,  0.0279, -0.0238,  0.0041,  0.0077, -0.0026, -0.0077,\n",
       "           -0.0373, -0.0286,  0.0051,  0.0173,  0.0339, -0.0096,  0.0250,\n",
       "           -0.0051,  0.0154,  0.0552, -0.0327,  0.0213]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[-0.0145,  0.0309, -0.0396, -0.0396,  0.0061, -0.0578, -0.0371,\n",
       "           -0.0003,  0.0192, -0.0266,  0.0281,  0.0472,  0.0193,  0.0305,\n",
       "            0.0088,  0.0285,  0.0411,  0.0486, -0.0054,  0.0353,  0.0074,\n",
       "           -0.0020, -0.0206,  0.0179,  0.0114,  0.0163,  0.0475,  0.0227,\n",
       "           -0.0088, -0.0038, -0.0409, -0.0082, -0.0274,  0.0081,  0.0226,\n",
       "            0.0391,  0.0172, -0.0190,  0.0318, -0.0281, -0.0162, -0.0019,\n",
       "            0.0453,  0.0165, -0.0131, -0.0075,  0.0241, -0.0514, -0.0406,\n",
       "            0.0061,  0.0367,  0.0460,  0.0184,  0.0310, -0.0242,  0.0079,\n",
       "            0.0023, -0.0096,  0.0070, -0.0030, -0.0152,  0.0055, -0.0117,\n",
       "            0.0111, -0.0188,  0.0111, -0.0086,  0.0035, -0.0077,  0.0207,\n",
       "           -0.0115, -0.0169,  0.0115, -0.0311,  0.0097, -0.0156, -0.0437,\n",
       "           -0.0026, -0.0129,  0.0274,  0.0281, -0.0245, -0.0023, -0.0158,\n",
       "           -0.0081, -0.0476, -0.0037, -0.0199, -0.0232, -0.0117, -0.0074,\n",
       "           -0.0137,  0.0106,  0.0108,  0.0216,  0.0030, -0.0030, -0.0355,\n",
       "            0.0401, -0.0182,  0.0251, -0.0057, -0.0363,  0.0501, -0.0030,\n",
       "            0.0102, -0.0192,  0.0257, -0.0397,  0.0006, -0.0144, -0.0187,\n",
       "            0.0046,  0.0299,  0.0057, -0.0279,  0.0113,  0.0078, -0.0090,\n",
       "            0.0501, -0.0002, -0.0362,  0.0273,  0.0340,  0.0271,  0.0276,\n",
       "            0.0101,  0.0067,  0.0307, -0.0297, -0.0522, -0.0100,  0.0118,\n",
       "            0.0516, -0.0066, -0.0053, -0.0200, -0.0277, -0.0124, -0.0222,\n",
       "           -0.0250, -0.0379, -0.0082,  0.0238, -0.0043,  0.0013,  0.0089,\n",
       "           -0.0155, -0.0152, -0.0229, -0.0177, -0.0171,  0.0163, -0.0153,\n",
       "            0.0330,  0.0026, -0.0386,  0.0141, -0.0296,  0.0273, -0.0499,\n",
       "            0.0102,  0.0386, -0.0079, -0.0308, -0.0290, -0.0292,  0.0348,\n",
       "            0.0386, -0.0166, -0.0071,  0.0398, -0.0040, -0.0574, -0.0076,\n",
       "           -0.0283, -0.0254, -0.0132,  0.0624, -0.0269, -0.0313, -0.0281,\n",
       "            0.0300, -0.0349,  0.0169, -0.0043, -0.0258, -0.0152, -0.0668,\n",
       "           -0.0278,  0.0549, -0.0062,  0.0092,  0.0054, -0.0144, -0.0101,\n",
       "            0.0341,  0.0030,  0.0203,  0.0255,  0.0046,  0.0495, -0.0164,\n",
       "           -0.0130,  0.0039,  0.0068,  0.0210, -0.0319, -0.0296, -0.0013,\n",
       "            0.0321,  0.0039, -0.0231,  0.0168, -0.0093, -0.0023,  0.0281,\n",
       "           -0.0445,  0.0399,  0.0140,  0.0304, -0.0325, -0.0041, -0.0377,\n",
       "            0.0272, -0.0605,  0.0216, -0.0104,  0.0156, -0.0305,  0.0197,\n",
       "            0.0209,  0.0283, -0.0252,  0.0059,  0.0058, -0.0031, -0.0067,\n",
       "           -0.0421, -0.0306,  0.0061,  0.0200,  0.0333, -0.0081,  0.0217,\n",
       "           -0.0036,  0.0132,  0.0545, -0.0332,  0.0221]]],\n",
       "        grad_fn=<StackBackward>)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0476],\n",
       "        [0.1000],\n",
       "        [0.1538],\n",
       "        [0.1852],\n",
       "        [0.1860],\n",
       "        [0.2632],\n",
       "        [0.4667],\n",
       "        [0.0588],\n",
       "        [0.3750],\n",
       "        [0.4000],\n",
       "        [0.4054],\n",
       "        [0.2093],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test_Tempest] *",
   "language": "python",
   "name": "conda-env-test_Tempest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
